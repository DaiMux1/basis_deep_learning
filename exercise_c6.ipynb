{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "exercise_c6.ipynb",
      "provenance": [],
      "mount_file_id": "1JBFFBb-3mqeJb_I6Kf8kkN6mYfObmHYi",
      "authorship_tag": "ABX9TyPKRA9028DYDy0OnBEHcRKg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dai02012000/basis_deep_learning/blob/main/exercise_c6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ir8vXOZzic0",
        "outputId": "0b37d366-fead-4158-ee74-d739a556cd16"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "gHxFuQ8pzlfK",
        "outputId": "c0c115a7-6153-45d6-99bb-ee148c000773"
      },
      "source": [
        "# đọc cvs \n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/dlwpt-code/data/p1ch4/tabular-wine/winequality-white.csv', delimiter=';')\n",
        "df"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>volatile acidity</th>\n",
              "      <th>citric acid</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free sulfur dioxide</th>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>quality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.0</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.36</td>\n",
              "      <td>20.7</td>\n",
              "      <td>0.045</td>\n",
              "      <td>45.0</td>\n",
              "      <td>170.0</td>\n",
              "      <td>1.00100</td>\n",
              "      <td>3.00</td>\n",
              "      <td>0.45</td>\n",
              "      <td>8.8</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6.3</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.34</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.049</td>\n",
              "      <td>14.0</td>\n",
              "      <td>132.0</td>\n",
              "      <td>0.99400</td>\n",
              "      <td>3.30</td>\n",
              "      <td>0.49</td>\n",
              "      <td>9.5</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8.1</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.40</td>\n",
              "      <td>6.9</td>\n",
              "      <td>0.050</td>\n",
              "      <td>30.0</td>\n",
              "      <td>97.0</td>\n",
              "      <td>0.99510</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.44</td>\n",
              "      <td>10.1</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7.2</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.32</td>\n",
              "      <td>8.5</td>\n",
              "      <td>0.058</td>\n",
              "      <td>47.0</td>\n",
              "      <td>186.0</td>\n",
              "      <td>0.99560</td>\n",
              "      <td>3.19</td>\n",
              "      <td>0.40</td>\n",
              "      <td>9.9</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.2</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.32</td>\n",
              "      <td>8.5</td>\n",
              "      <td>0.058</td>\n",
              "      <td>47.0</td>\n",
              "      <td>186.0</td>\n",
              "      <td>0.99560</td>\n",
              "      <td>3.19</td>\n",
              "      <td>0.40</td>\n",
              "      <td>9.9</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4893</th>\n",
              "      <td>6.2</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.29</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.039</td>\n",
              "      <td>24.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>0.99114</td>\n",
              "      <td>3.27</td>\n",
              "      <td>0.50</td>\n",
              "      <td>11.2</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4894</th>\n",
              "      <td>6.6</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.36</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.047</td>\n",
              "      <td>57.0</td>\n",
              "      <td>168.0</td>\n",
              "      <td>0.99490</td>\n",
              "      <td>3.15</td>\n",
              "      <td>0.46</td>\n",
              "      <td>9.6</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4895</th>\n",
              "      <td>6.5</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.19</td>\n",
              "      <td>1.2</td>\n",
              "      <td>0.041</td>\n",
              "      <td>30.0</td>\n",
              "      <td>111.0</td>\n",
              "      <td>0.99254</td>\n",
              "      <td>2.99</td>\n",
              "      <td>0.46</td>\n",
              "      <td>9.4</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4896</th>\n",
              "      <td>5.5</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.30</td>\n",
              "      <td>1.1</td>\n",
              "      <td>0.022</td>\n",
              "      <td>20.0</td>\n",
              "      <td>110.0</td>\n",
              "      <td>0.98869</td>\n",
              "      <td>3.34</td>\n",
              "      <td>0.38</td>\n",
              "      <td>12.8</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4897</th>\n",
              "      <td>6.0</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.020</td>\n",
              "      <td>22.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>0.98941</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.32</td>\n",
              "      <td>11.8</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4898 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      fixed acidity  volatile acidity  citric acid  ...  sulphates  alcohol  quality\n",
              "0               7.0              0.27         0.36  ...       0.45      8.8        6\n",
              "1               6.3              0.30         0.34  ...       0.49      9.5        6\n",
              "2               8.1              0.28         0.40  ...       0.44     10.1        6\n",
              "3               7.2              0.23         0.32  ...       0.40      9.9        6\n",
              "4               7.2              0.23         0.32  ...       0.40      9.9        6\n",
              "...             ...               ...          ...  ...        ...      ...      ...\n",
              "4893            6.2              0.21         0.29  ...       0.50     11.2        6\n",
              "4894            6.6              0.32         0.36  ...       0.46      9.6        5\n",
              "4895            6.5              0.24         0.19  ...       0.46      9.4        6\n",
              "4896            5.5              0.29         0.30  ...       0.38     12.8        7\n",
              "4897            6.0              0.21         0.38  ...       0.32     11.8        6\n",
              "\n",
              "[4898 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwi889DO8ahc",
        "outputId": "c48d1205-a84d-422d-9e90-a784f8d15382"
      },
      "source": [
        "# chuyển vể torch tensor\n",
        "import torch\n",
        "\n",
        "wine_tensor = torch.tensor(df.values, dtype=torch.float32)\n",
        "wine_tensor\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 7.0000,  0.2700,  0.3600,  ...,  0.4500,  8.8000,  6.0000],\n",
              "        [ 6.3000,  0.3000,  0.3400,  ...,  0.4900,  9.5000,  6.0000],\n",
              "        [ 8.1000,  0.2800,  0.4000,  ...,  0.4400, 10.1000,  6.0000],\n",
              "        ...,\n",
              "        [ 6.5000,  0.2400,  0.1900,  ...,  0.4600,  9.4000,  6.0000],\n",
              "        [ 5.5000,  0.2900,  0.3000,  ...,  0.3800, 12.8000,  7.0000],\n",
              "        [ 6.0000,  0.2100,  0.3800,  ...,  0.3200, 11.8000,  6.0000]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvk9YEr46-96",
        "outputId": "4f255e2f-8ebf-466d-e713-1e5e2f1639f5"
      },
      "source": [
        "# chia data, và target, target là điểm số đánh giá về rượu dựa trên thành phần của rượu\n",
        "data = wine_tensor[:, :-1]\n",
        "target = wine_tensor[:, -1]\n",
        "data.shape, target.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([4898, 11]), torch.Size([4898]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjn2ruT07RCz",
        "outputId": "3b474948-3f0b-4a2b-99d4-b0e86e342987"
      },
      "source": [
        "# thêm 1 chiều để đúng dim với data, phục vụ cho chia batch  \n",
        "target = target.unsqueeze(1)\n",
        "target.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4898, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIt76HV-7iHZ",
        "outputId": "5b59d60d-7025-4ada-8080-d4b5673b4aef"
      },
      "source": [
        "# random index để chia tập train, val\n",
        "examples = data.shape[0]\n",
        "p = torch.randperm(examples)\n",
        "ind_val = int(0.2 * examples)\n",
        "\n",
        "ind_train = p[:-ind_val]\n",
        "ind_val = p[-ind_val:]\n",
        "\n",
        "ind_val.shape, ind_train.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([979]), torch.Size([3919]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZTY0GXL-igi",
        "outputId": "3bdfb59e-0a1c-44b0-d27a-df819c48a3eb"
      },
      "source": [
        "\n",
        "# chia tập train, val\n",
        "train_data = data[ind_train]\n",
        "val_data = data[ind_val]\n",
        "\n",
        "train_target = target[ind_train]\n",
        "val_target = target[ind_val]\n",
        "\n",
        "train_data.shape, val_data.shape, train_target.shape, val_target.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([3919, 11]),\n",
              " torch.Size([979, 11]),\n",
              " torch.Size([3919, 1]),\n",
              " torch.Size([979, 1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRYRacRxDcVk",
        "outputId": "17c2f01a-a69d-45cd-a260-d5265174fece"
      },
      "source": [
        "# chia\n",
        "batch_size = 16\n",
        "\n",
        "train_data_loader = []\n",
        "val_data_loader = []\n",
        "train_target_loader = []\n",
        "val_target_loader = []\n",
        "\n",
        "iter_train = int(train_data.shape[0]/batch_size)\n",
        "for i in range(1, iter_train+2):\n",
        "  train_data_batch = train_data[(i-1)*batch_size : i*batch_size]\n",
        "  train_target_batch = train_target[(i-1)*batch_size : i*batch_size]\n",
        "\n",
        "  train_data_loader.append(train_data_batch)\n",
        "  train_target_loader.append(train_target_batch)\n",
        "  \n",
        "iter_val = int(val_data.shape[0]/batch_size)\n",
        "for i in range(1, iter_val+2):\n",
        "  val_data_batch = val_data[(i-1)*batch_size : i*batch_size]\n",
        "  val_target_batch = val_target[(i-1)*batch_size : i*batch_size]\n",
        "\n",
        "  val_data_loader.append(val_data_batch)\n",
        "  val_target_loader.append(val_target_batch)\n",
        "\n",
        "\n",
        "len(train_data_loader), len(val_data_loader), len(train_target_loader), len(val_target_loader),train_data_loader[0]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(245,\n",
              " 62,\n",
              " 245,\n",
              " 62,\n",
              " tensor([[7.7000e+00, 3.9000e-01, 4.9000e-01, 7.7000e+00, 3.6000e-02, 1.1000e+01,\n",
              "          1.1000e+02, 9.9660e-01, 3.3300e+00, 7.6000e-01, 1.0000e+01],\n",
              "         [5.6000e+00, 3.4000e-01, 1.0000e-01, 1.3000e+00, 3.1000e-02, 2.0000e+01,\n",
              "          6.8000e+01, 9.9060e-01, 3.3600e+00, 5.1000e-01, 1.1200e+01],\n",
              "         [7.6000e+00, 4.7000e-01, 4.9000e-01, 1.3000e+01, 2.3900e-01, 4.2000e+01,\n",
              "          2.2000e+02, 9.9880e-01, 2.9600e+00, 5.1000e-01, 9.2000e+00],\n",
              "         [6.3000e+00, 3.5000e-01, 3.0000e-01, 5.7000e+00, 3.5000e-02, 8.0000e+00,\n",
              "          9.7000e+01, 9.9270e-01, 3.2700e+00, 4.1000e-01, 1.1000e+01],\n",
              "         [7.6000e+00, 1.9000e-01, 4.1000e-01, 1.1000e+00, 4.0000e-02, 3.8000e+01,\n",
              "          1.4300e+02, 9.9070e-01, 2.9200e+00, 4.2000e-01, 1.1400e+01],\n",
              "         [5.8000e+00, 2.8000e-01, 3.0000e-01, 3.9000e+00, 2.6000e-02, 3.6000e+01,\n",
              "          1.0500e+02, 9.8963e-01, 3.2600e+00, 5.8000e-01, 1.2750e+01],\n",
              "         [7.3000e+00, 2.0000e-01, 3.7000e-01, 1.2000e+00, 3.7000e-02, 4.8000e+01,\n",
              "          1.1900e+02, 9.9200e-01, 3.3200e+00, 4.9000e-01, 1.0900e+01],\n",
              "         [7.3000e+00, 2.6000e-01, 3.3000e-01, 1.7850e+01, 4.9000e-02, 4.1500e+01,\n",
              "          1.9500e+02, 1.0000e+00, 3.0600e+00, 4.4000e-01, 9.1000e+00],\n",
              "         [6.9000e+00, 3.2000e-01, 1.3000e-01, 7.8000e+00, 4.2000e-02, 1.1000e+01,\n",
              "          1.1700e+02, 9.9600e-01, 3.2300e+00, 3.7000e-01, 9.2000e+00],\n",
              "         [6.2000e+00, 3.0000e-01, 1.7000e-01, 2.8000e+00, 4.0000e-02, 2.4000e+01,\n",
              "          1.2500e+02, 9.9390e-01, 3.0100e+00, 4.6000e-01, 9.0000e+00],\n",
              "         [6.1000e+00, 1.7000e-01, 2.7000e-01, 1.5000e+00, 5.6000e-02, 4.5000e+01,\n",
              "          1.3500e+02, 9.9240e-01, 3.2000e+00, 4.3000e-01, 1.0200e+01],\n",
              "         [6.3000e+00, 3.0000e-01, 2.4000e-01, 6.6000e+00, 4.0000e-02, 3.8000e+01,\n",
              "          1.4100e+02, 9.9500e-01, 3.2200e+00, 4.7000e-01, 9.5000e+00],\n",
              "         [6.2000e+00, 3.6000e-01, 1.4000e-01, 8.9000e+00, 3.6000e-02, 3.8000e+01,\n",
              "          1.5500e+02, 9.9622e-01, 3.2700e+00, 5.0000e-01, 9.4000e+00],\n",
              "         [8.0000e+00, 3.0000e-01, 4.9000e-01, 9.4000e+00, 4.6000e-02, 4.7000e+01,\n",
              "          1.8800e+02, 9.9640e-01, 3.1400e+00, 4.8000e-01, 1.0000e+01],\n",
              "         [8.0000e+00, 2.8000e-01, 4.2000e-01, 7.1000e+00, 4.5000e-02, 4.1000e+01,\n",
              "          1.6900e+02, 9.9590e-01, 3.1700e+00, 4.3000e-01, 1.0600e+01],\n",
              "         [6.8000e+00, 1.8000e-01, 2.8000e-01, 9.8000e+00, 3.9000e-02, 2.9000e+01,\n",
              "          1.1300e+02, 9.9406e-01, 3.1100e+00, 4.5000e-01, 1.0900e+01]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5I8Jl0dAzrO",
        "outputId": "75bd2d52-bd99-41fd-e2c5-734c91e9656a"
      },
      "source": [
        "# model \n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class SubClassFunctionalModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.hidden_linear1 = nn.Linear(11, 1)\n",
        "    # self.hidden_linear2 = nn.Linear(100, 100)\n",
        "    # self.output_linear = nn.Linear(50, 1)\n",
        "\n",
        "  def forward(self, input):\n",
        "    # hidden_t = self.hidden_linear1(input)\n",
        "    # activated_t = torch.tanh(hidden_t)\n",
        "    # output_t = self.hidden_linear2(activated_t)\n",
        "    # output_t = torch.tanh(output_t)\n",
        "    output_t = self.hidden_linear1(input)\n",
        "\n",
        "    return output_t\n",
        "\n",
        "func_model = SubClassFunctionalModel()\n",
        "func_model.parameters"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Module.parameters of SubClassFunctionalModel(\n",
              "  (hidden_linear1): Linear(in_features=11, out_features=1, bias=True)\n",
              ")>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOT4Dstq5OyE"
      },
      "source": [
        "list_loss_train = []\n",
        "list_loss_test = []"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmdxl5X3DJVe"
      },
      "source": [
        "def train(optimizer, model, loss_fn, train_data_loader, train_target_loader, epoch):\n",
        "  for iter, (data, target) in enumerate(zip(train_data_loader, train_target_loader)):\n",
        "    train_target_p = model(data)\n",
        "    loss_train = loss_fn(train_target_p, target)\n",
        "    list_loss_train.append(loss_train)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss_train.backward()\n",
        "    optimizer.step()\n",
        "    if iter % 20 == 0:\n",
        "      print(\"Train Epoch: {} [{}/{}] \\tLoss: {:.6f} \".format(\n",
        "          epoch, iter , len(train_data_loader), loss_train.item()\n",
        "      ))"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KkybkXiNFFr"
      },
      "source": [
        "def test(model, loss_fn, val_data_loader, val_target_loader):\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "  with torch.no_grad():\n",
        "    for ind, (data, target) in enumerate(zip(val_data_loader, val_target_loader)):\n",
        "      # print(ind)\n",
        "      # print(data.shape, target.shape)\n",
        "      output = model(data)\n",
        "      test_loss += loss_fn(output, target)\n",
        "      # print(loss_fn(output, target))\n",
        "      # if torch.isnan(loss_fn(output, target)):\n",
        "      #   print(data)\n",
        "      #   print(output)\n",
        "      #   print(target)\n",
        "        \n",
        "\n",
        "\n",
        "      # print(loss_fn(output, target))\n",
        "      # print(test_loss)\n",
        "      \n",
        "      output = output.to(torch.int32)\n",
        "      correct += output.eq(target.view_as(output)).sum().item()\n",
        "      \n",
        "  test_loss /= len(val_data_loader) \n",
        "  list_loss_test.append(test_loss)\n",
        "  print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(val_data_loader)*batch_size,\n",
        "        100. * correct / (len(val_data_loader)*batch_size)))"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSEXHJgMJIpC",
        "outputId": "a7dc9603-126c-4310-fbf6-d323ab0b05bd"
      },
      "source": [
        "\n",
        "optimizer = optim.Adam(func_model.parameters(), lr=0.005)\n",
        "\n",
        "for epoch in range(1, 100):\n",
        "  train(optimizer,func_model, nn.MSELoss(), train_data_loader, train_target_loader, epoch)\n",
        "  test(func_model, nn.MSELoss(), val_data_loader, val_target_loader)\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/245] \tLoss: 42.227596 \n",
            "Train Epoch: 1 [20/245] \tLoss: 4.399013 \n",
            "Train Epoch: 1 [40/245] \tLoss: 4.179076 \n",
            "Train Epoch: 1 [60/245] \tLoss: 9.293327 \n",
            "Train Epoch: 1 [80/245] \tLoss: 3.299748 \n",
            "Train Epoch: 1 [100/245] \tLoss: 1.808498 \n",
            "Train Epoch: 1 [120/245] \tLoss: 0.927483 \n",
            "Train Epoch: 1 [140/245] \tLoss: 2.501730 \n",
            "Train Epoch: 1 [160/245] \tLoss: 1.261050 \n",
            "Train Epoch: 1 [180/245] \tLoss: 0.493297 \n",
            "Train Epoch: 1 [200/245] \tLoss: 1.038398 \n",
            "Train Epoch: 1 [220/245] \tLoss: 0.601000 \n",
            "Train Epoch: 1 [240/245] \tLoss: 1.449217 \n",
            "\n",
            "Test set: Average loss: 0.7938, Accuracy: 295/992 (30%)\n",
            "\n",
            "Train Epoch: 2 [0/245] \tLoss: 0.866032 \n",
            "Train Epoch: 2 [20/245] \tLoss: 1.269039 \n",
            "Train Epoch: 2 [40/245] \tLoss: 0.546934 \n",
            "Train Epoch: 2 [60/245] \tLoss: 0.954867 \n",
            "Train Epoch: 2 [80/245] \tLoss: 0.523205 \n",
            "Train Epoch: 2 [100/245] \tLoss: 0.632415 \n",
            "Train Epoch: 2 [120/245] \tLoss: 0.668409 \n",
            "Train Epoch: 2 [140/245] \tLoss: 0.874781 \n",
            "Train Epoch: 2 [160/245] \tLoss: 0.449924 \n",
            "Train Epoch: 2 [180/245] \tLoss: 0.435196 \n",
            "Train Epoch: 2 [200/245] \tLoss: 0.822887 \n",
            "Train Epoch: 2 [220/245] \tLoss: 0.449735 \n",
            "Train Epoch: 2 [240/245] \tLoss: 0.957789 \n",
            "\n",
            "Test set: Average loss: 0.6920, Accuracy: 329/992 (33%)\n",
            "\n",
            "Train Epoch: 3 [0/245] \tLoss: 0.651356 \n",
            "Train Epoch: 3 [20/245] \tLoss: 0.932686 \n",
            "Train Epoch: 3 [40/245] \tLoss: 0.497428 \n",
            "Train Epoch: 3 [60/245] \tLoss: 0.643294 \n",
            "Train Epoch: 3 [80/245] \tLoss: 0.548882 \n",
            "Train Epoch: 3 [100/245] \tLoss: 0.583885 \n",
            "Train Epoch: 3 [120/245] \tLoss: 0.663781 \n",
            "Train Epoch: 3 [140/245] \tLoss: 0.861145 \n",
            "Train Epoch: 3 [160/245] \tLoss: 0.442447 \n",
            "Train Epoch: 3 [180/245] \tLoss: 0.442819 \n",
            "Train Epoch: 3 [200/245] \tLoss: 0.834517 \n",
            "Train Epoch: 3 [220/245] \tLoss: 0.462698 \n",
            "Train Epoch: 3 [240/245] \tLoss: 0.873424 \n",
            "\n",
            "Test set: Average loss: 0.6257, Accuracy: 362/992 (36%)\n",
            "\n",
            "Train Epoch: 4 [0/245] \tLoss: 0.596467 \n",
            "Train Epoch: 4 [20/245] \tLoss: 0.951205 \n",
            "Train Epoch: 4 [40/245] \tLoss: 0.482013 \n",
            "Train Epoch: 4 [60/245] \tLoss: 0.636759 \n",
            "Train Epoch: 4 [80/245] \tLoss: 0.600544 \n",
            "Train Epoch: 4 [100/245] \tLoss: 0.577363 \n",
            "Train Epoch: 4 [120/245] \tLoss: 0.643952 \n",
            "Train Epoch: 4 [140/245] \tLoss: 0.805101 \n",
            "Train Epoch: 4 [160/245] \tLoss: 0.429911 \n",
            "Train Epoch: 4 [180/245] \tLoss: 0.447620 \n",
            "Train Epoch: 4 [200/245] \tLoss: 0.881475 \n",
            "Train Epoch: 4 [220/245] \tLoss: 0.480293 \n",
            "Train Epoch: 4 [240/245] \tLoss: 0.842399 \n",
            "\n",
            "Test set: Average loss: 0.5895, Accuracy: 408/992 (41%)\n",
            "\n",
            "Train Epoch: 5 [0/245] \tLoss: 0.580300 \n",
            "Train Epoch: 5 [20/245] \tLoss: 1.046160 \n",
            "Train Epoch: 5 [40/245] \tLoss: 0.468661 \n",
            "Train Epoch: 5 [60/245] \tLoss: 0.635307 \n",
            "Train Epoch: 5 [80/245] \tLoss: 0.587286 \n",
            "Train Epoch: 5 [100/245] \tLoss: 0.545482 \n",
            "Train Epoch: 5 [120/245] \tLoss: 0.626498 \n",
            "Train Epoch: 5 [140/245] \tLoss: 0.739316 \n",
            "Train Epoch: 5 [160/245] \tLoss: 0.414479 \n",
            "Train Epoch: 5 [180/245] \tLoss: 0.447976 \n",
            "Train Epoch: 5 [200/245] \tLoss: 0.927999 \n",
            "Train Epoch: 5 [220/245] \tLoss: 0.477804 \n",
            "Train Epoch: 5 [240/245] \tLoss: 0.851601 \n",
            "\n",
            "Test set: Average loss: 0.5987, Accuracy: 451/992 (45%)\n",
            "\n",
            "Train Epoch: 6 [0/245] \tLoss: 0.618440 \n",
            "Train Epoch: 6 [20/245] \tLoss: 1.156661 \n",
            "Train Epoch: 6 [40/245] \tLoss: 0.460845 \n",
            "Train Epoch: 6 [60/245] \tLoss: 0.644664 \n",
            "Train Epoch: 6 [80/245] \tLoss: 0.561115 \n",
            "Train Epoch: 6 [100/245] \tLoss: 0.530990 \n",
            "Train Epoch: 6 [120/245] \tLoss: 0.613632 \n",
            "Train Epoch: 6 [140/245] \tLoss: 0.704464 \n",
            "Train Epoch: 6 [160/245] \tLoss: 0.400783 \n",
            "Train Epoch: 6 [180/245] \tLoss: 0.448083 \n",
            "Train Epoch: 6 [200/245] \tLoss: 0.961118 \n",
            "Train Epoch: 6 [220/245] \tLoss: 0.469437 \n",
            "Train Epoch: 6 [240/245] \tLoss: 0.880424 \n",
            "\n",
            "Test set: Average loss: 0.6521, Accuracy: 479/992 (48%)\n",
            "\n",
            "Train Epoch: 7 [0/245] \tLoss: 0.693757 \n",
            "Train Epoch: 7 [20/245] \tLoss: 1.225462 \n",
            "Train Epoch: 7 [40/245] \tLoss: 0.459865 \n",
            "Train Epoch: 7 [60/245] \tLoss: 0.663223 \n",
            "Train Epoch: 7 [80/245] \tLoss: 0.548628 \n",
            "Train Epoch: 7 [100/245] \tLoss: 0.527973 \n",
            "Train Epoch: 7 [120/245] \tLoss: 0.603344 \n",
            "Train Epoch: 7 [140/245] \tLoss: 0.678219 \n",
            "Train Epoch: 7 [160/245] \tLoss: 0.388149 \n",
            "Train Epoch: 7 [180/245] \tLoss: 0.447025 \n",
            "Train Epoch: 7 [200/245] \tLoss: 0.980316 \n",
            "Train Epoch: 7 [220/245] \tLoss: 0.464603 \n",
            "Train Epoch: 7 [240/245] \tLoss: 0.905614 \n",
            "\n",
            "Test set: Average loss: 0.7172, Accuracy: 483/992 (49%)\n",
            "\n",
            "Train Epoch: 8 [0/245] \tLoss: 0.770907 \n",
            "Train Epoch: 8 [20/245] \tLoss: 1.252850 \n",
            "Train Epoch: 8 [40/245] \tLoss: 0.464570 \n",
            "Train Epoch: 8 [60/245] \tLoss: 0.680497 \n",
            "Train Epoch: 8 [80/245] \tLoss: 0.544725 \n",
            "Train Epoch: 8 [100/245] \tLoss: 0.527618 \n",
            "Train Epoch: 8 [120/245] \tLoss: 0.595721 \n",
            "Train Epoch: 8 [140/245] \tLoss: 0.653941 \n",
            "Train Epoch: 8 [160/245] \tLoss: 0.376478 \n",
            "Train Epoch: 8 [180/245] \tLoss: 0.445223 \n",
            "Train Epoch: 8 [200/245] \tLoss: 0.991016 \n",
            "Train Epoch: 8 [220/245] \tLoss: 0.463513 \n",
            "Train Epoch: 8 [240/245] \tLoss: 0.921707 \n",
            "\n",
            "Test set: Average loss: 0.7755, Accuracy: 492/992 (50%)\n",
            "\n",
            "Train Epoch: 9 [0/245] \tLoss: 0.834506 \n",
            "Train Epoch: 9 [20/245] \tLoss: 1.258338 \n",
            "Train Epoch: 9 [40/245] \tLoss: 0.471733 \n",
            "Train Epoch: 9 [60/245] \tLoss: 0.692307 \n",
            "Train Epoch: 9 [80/245] \tLoss: 0.544090 \n",
            "Train Epoch: 9 [100/245] \tLoss: 0.528008 \n",
            "Train Epoch: 9 [120/245] \tLoss: 0.590028 \n",
            "Train Epoch: 9 [140/245] \tLoss: 0.632759 \n",
            "Train Epoch: 9 [160/245] \tLoss: 0.365791 \n",
            "Train Epoch: 9 [180/245] \tLoss: 0.443087 \n",
            "Train Epoch: 9 [200/245] \tLoss: 0.996715 \n",
            "Train Epoch: 9 [220/245] \tLoss: 0.464523 \n",
            "Train Epoch: 9 [240/245] \tLoss: 0.930319 \n",
            "\n",
            "Test set: Average loss: 0.8225, Accuracy: 504/992 (51%)\n",
            "\n",
            "Train Epoch: 10 [0/245] \tLoss: 0.883018 \n",
            "Train Epoch: 10 [20/245] \tLoss: 1.255001 \n",
            "Train Epoch: 10 [40/245] \tLoss: 0.478947 \n",
            "Train Epoch: 10 [60/245] \tLoss: 0.699230 \n",
            "Train Epoch: 10 [80/245] \tLoss: 0.544580 \n",
            "Train Epoch: 10 [100/245] \tLoss: 0.528863 \n",
            "Train Epoch: 10 [120/245] \tLoss: 0.585526 \n",
            "Train Epoch: 10 [140/245] \tLoss: 0.615278 \n",
            "Train Epoch: 10 [160/245] \tLoss: 0.356095 \n",
            "Train Epoch: 10 [180/245] \tLoss: 0.440862 \n",
            "Train Epoch: 10 [200/245] \tLoss: 0.999487 \n",
            "Train Epoch: 10 [220/245] \tLoss: 0.466450 \n",
            "Train Epoch: 10 [240/245] \tLoss: 0.933947 \n",
            "\n",
            "Test set: Average loss: 0.8590, Accuracy: 509/992 (51%)\n",
            "\n",
            "Train Epoch: 11 [0/245] \tLoss: 0.919090 \n",
            "Train Epoch: 11 [20/245] \tLoss: 1.248990 \n",
            "Train Epoch: 11 [40/245] \tLoss: 0.485173 \n",
            "Train Epoch: 11 [60/245] \tLoss: 0.702817 \n",
            "Train Epoch: 11 [80/245] \tLoss: 0.545423 \n",
            "Train Epoch: 11 [100/245] \tLoss: 0.530091 \n",
            "Train Epoch: 11 [120/245] \tLoss: 0.581786 \n",
            "Train Epoch: 11 [140/245] \tLoss: 0.601214 \n",
            "Train Epoch: 11 [160/245] \tLoss: 0.347368 \n",
            "Train Epoch: 11 [180/245] \tLoss: 0.438705 \n",
            "Train Epoch: 11 [200/245] \tLoss: 1.000587 \n",
            "Train Epoch: 11 [220/245] \tLoss: 0.468666 \n",
            "Train Epoch: 11 [240/245] \tLoss: 0.934509 \n",
            "\n",
            "Test set: Average loss: 0.8872, Accuracy: 501/992 (51%)\n",
            "\n",
            "Train Epoch: 12 [0/245] \tLoss: 0.945798 \n",
            "Train Epoch: 12 [20/245] \tLoss: 1.242793 \n",
            "Train Epoch: 12 [40/245] \tLoss: 0.490174 \n",
            "Train Epoch: 12 [60/245] \tLoss: 0.704338 \n",
            "Train Epoch: 12 [80/245] \tLoss: 0.546338 \n",
            "Train Epoch: 12 [100/245] \tLoss: 0.531607 \n",
            "Train Epoch: 12 [120/245] \tLoss: 0.578587 \n",
            "Train Epoch: 12 [140/245] \tLoss: 0.589989 \n",
            "Train Epoch: 12 [160/245] \tLoss: 0.339564 \n",
            "Train Epoch: 12 [180/245] \tLoss: 0.436713 \n",
            "Train Epoch: 12 [200/245] \tLoss: 1.000766 \n",
            "Train Epoch: 12 [220/245] \tLoss: 0.470881 \n",
            "Train Epoch: 12 [240/245] \tLoss: 0.933278 \n",
            "\n",
            "Test set: Average loss: 0.9090, Accuracy: 503/992 (51%)\n",
            "\n",
            "Train Epoch: 13 [0/245] \tLoss: 0.965667 \n",
            "Train Epoch: 13 [20/245] \tLoss: 1.237276 \n",
            "Train Epoch: 13 [40/245] \tLoss: 0.494044 \n",
            "Train Epoch: 13 [60/245] \tLoss: 0.704643 \n",
            "Train Epoch: 13 [80/245] \tLoss: 0.547224 \n",
            "Train Epoch: 13 [100/245] \tLoss: 0.533328 \n",
            "Train Epoch: 13 [120/245] \tLoss: 0.575811 \n",
            "Train Epoch: 13 [140/245] \tLoss: 0.581019 \n",
            "Train Epoch: 13 [160/245] \tLoss: 0.332620 \n",
            "Train Epoch: 13 [180/245] \tLoss: 0.434936 \n",
            "Train Epoch: 13 [200/245] \tLoss: 1.000464 \n",
            "Train Epoch: 13 [220/245] \tLoss: 0.472985 \n",
            "Train Epoch: 13 [240/245] \tLoss: 0.931052 \n",
            "\n",
            "Test set: Average loss: 0.9261, Accuracy: 499/992 (50%)\n",
            "\n",
            "Train Epoch: 14 [0/245] \tLoss: 0.980574 \n",
            "Train Epoch: 14 [20/245] \tLoss: 1.232635 \n",
            "Train Epoch: 14 [40/245] \tLoss: 0.496977 \n",
            "Train Epoch: 14 [60/245] \tLoss: 0.704258 \n",
            "Train Epoch: 14 [80/245] \tLoss: 0.548045 \n",
            "Train Epoch: 14 [100/245] \tLoss: 0.535182 \n",
            "Train Epoch: 14 [120/245] \tLoss: 0.573387 \n",
            "Train Epoch: 14 [140/245] \tLoss: 0.573817 \n",
            "Train Epoch: 14 [160/245] \tLoss: 0.326460 \n",
            "Train Epoch: 14 [180/245] \tLoss: 0.433391 \n",
            "Train Epoch: 14 [200/245] \tLoss: 0.999937 \n",
            "Train Epoch: 14 [220/245] \tLoss: 0.474947 \n",
            "Train Epoch: 14 [240/245] \tLoss: 0.928326 \n",
            "\n",
            "Test set: Average loss: 0.9397, Accuracy: 496/992 (50%)\n",
            "\n",
            "Train Epoch: 15 [0/245] \tLoss: 0.991879 \n",
            "Train Epoch: 15 [20/245] \tLoss: 1.228816 \n",
            "Train Epoch: 15 [40/245] \tLoss: 0.499172 \n",
            "Train Epoch: 15 [60/245] \tLoss: 0.703504 \n",
            "Train Epoch: 15 [80/245] \tLoss: 0.548790 \n",
            "Train Epoch: 15 [100/245] \tLoss: 0.537106 \n",
            "Train Epoch: 15 [120/245] \tLoss: 0.571267 \n",
            "Train Epoch: 15 [140/245] \tLoss: 0.567993 \n",
            "Train Epoch: 15 [160/245] \tLoss: 0.321009 \n",
            "Train Epoch: 15 [180/245] \tLoss: 0.432074 \n",
            "Train Epoch: 15 [200/245] \tLoss: 0.999331 \n",
            "Train Epoch: 15 [220/245] \tLoss: 0.476770 \n",
            "Train Epoch: 15 [240/245] \tLoss: 0.925397 \n",
            "\n",
            "Test set: Average loss: 0.9505, Accuracy: 503/992 (51%)\n",
            "\n",
            "Train Epoch: 16 [0/245] \tLoss: 1.000541 \n",
            "Train Epoch: 16 [20/245] \tLoss: 1.225690 \n",
            "Train Epoch: 16 [40/245] \tLoss: 0.500797 \n",
            "Train Epoch: 16 [60/245] \tLoss: 0.702568 \n",
            "Train Epoch: 16 [80/245] \tLoss: 0.549457 \n",
            "Train Epoch: 16 [100/245] \tLoss: 0.539051 \n",
            "Train Epoch: 16 [120/245] \tLoss: 0.569413 \n",
            "Train Epoch: 16 [140/245] \tLoss: 0.563247 \n",
            "Train Epoch: 16 [160/245] \tLoss: 0.316191 \n",
            "Train Epoch: 16 [180/245] \tLoss: 0.430968 \n",
            "Train Epoch: 16 [200/245] \tLoss: 0.998728 \n",
            "Train Epoch: 16 [220/245] \tLoss: 0.478469 \n",
            "Train Epoch: 16 [240/245] \tLoss: 0.922447 \n",
            "\n",
            "Test set: Average loss: 0.9594, Accuracy: 505/992 (51%)\n",
            "\n",
            "Train Epoch: 17 [0/245] \tLoss: 1.007253 \n",
            "Train Epoch: 17 [20/245] \tLoss: 1.223121 \n",
            "Train Epoch: 17 [40/245] \tLoss: 0.501986 \n",
            "Train Epoch: 17 [60/245] \tLoss: 0.701562 \n",
            "Train Epoch: 17 [80/245] \tLoss: 0.550050 \n",
            "Train Epoch: 17 [100/245] \tLoss: 0.540980 \n",
            "Train Epoch: 17 [120/245] \tLoss: 0.567793 \n",
            "Train Epoch: 17 [140/245] \tLoss: 0.559353 \n",
            "Train Epoch: 17 [160/245] \tLoss: 0.311934 \n",
            "Train Epoch: 17 [180/245] \tLoss: 0.430052 \n",
            "Train Epoch: 17 [200/245] \tLoss: 0.998174 \n",
            "Train Epoch: 17 [220/245] \tLoss: 0.480061 \n",
            "Train Epoch: 17 [240/245] \tLoss: 0.919583 \n",
            "\n",
            "Test set: Average loss: 0.9666, Accuracy: 504/992 (51%)\n",
            "\n",
            "Train Epoch: 18 [0/245] \tLoss: 1.012511 \n",
            "Train Epoch: 18 [20/245] \tLoss: 1.220989 \n",
            "Train Epoch: 18 [40/245] \tLoss: 0.502843 \n",
            "Train Epoch: 18 [60/245] \tLoss: 0.700551 \n",
            "Train Epoch: 18 [80/245] \tLoss: 0.550573 \n",
            "Train Epoch: 18 [100/245] \tLoss: 0.542864 \n",
            "Train Epoch: 18 [120/245] \tLoss: 0.566379 \n",
            "Train Epoch: 18 [140/245] \tLoss: 0.556134 \n",
            "Train Epoch: 18 [160/245] \tLoss: 0.308173 \n",
            "Train Epoch: 18 [180/245] \tLoss: 0.429302 \n",
            "Train Epoch: 18 [200/245] \tLoss: 0.997689 \n",
            "Train Epoch: 18 [220/245] \tLoss: 0.481560 \n",
            "Train Epoch: 18 [240/245] \tLoss: 0.916862 \n",
            "\n",
            "Test set: Average loss: 0.9727, Accuracy: 508/992 (51%)\n",
            "\n",
            "Train Epoch: 19 [0/245] \tLoss: 1.016678 \n",
            "Train Epoch: 19 [20/245] \tLoss: 1.219195 \n",
            "Train Epoch: 19 [40/245] \tLoss: 0.503448 \n",
            "Train Epoch: 19 [60/245] \tLoss: 0.699569 \n",
            "Train Epoch: 19 [80/245] \tLoss: 0.551030 \n",
            "Train Epoch: 19 [100/245] \tLoss: 0.544681 \n",
            "Train Epoch: 19 [120/245] \tLoss: 0.565147 \n",
            "Train Epoch: 19 [140/245] \tLoss: 0.553458 \n",
            "Train Epoch: 19 [160/245] \tLoss: 0.304849 \n",
            "Train Epoch: 19 [180/245] \tLoss: 0.428696 \n",
            "Train Epoch: 19 [200/245] \tLoss: 0.997278 \n",
            "Train Epoch: 19 [220/245] \tLoss: 0.482977 \n",
            "Train Epoch: 19 [240/245] \tLoss: 0.914317 \n",
            "\n",
            "Test set: Average loss: 0.9778, Accuracy: 505/992 (51%)\n",
            "\n",
            "Train Epoch: 20 [0/245] \tLoss: 1.020010 \n",
            "Train Epoch: 20 [20/245] \tLoss: 1.217661 \n",
            "Train Epoch: 20 [40/245] \tLoss: 0.503861 \n",
            "Train Epoch: 20 [60/245] \tLoss: 0.698634 \n",
            "Train Epoch: 20 [80/245] \tLoss: 0.551427 \n",
            "Train Epoch: 20 [100/245] \tLoss: 0.546418 \n",
            "Train Epoch: 20 [120/245] \tLoss: 0.564073 \n",
            "Train Epoch: 20 [140/245] \tLoss: 0.551219 \n",
            "Train Epoch: 20 [160/245] \tLoss: 0.301909 \n",
            "Train Epoch: 20 [180/245] \tLoss: 0.428210 \n",
            "Train Epoch: 20 [200/245] \tLoss: 0.996943 \n",
            "Train Epoch: 20 [220/245] \tLoss: 0.484320 \n",
            "Train Epoch: 20 [240/245] \tLoss: 0.911959 \n",
            "\n",
            "Test set: Average loss: 0.9821, Accuracy: 504/992 (51%)\n",
            "\n",
            "Train Epoch: 21 [0/245] \tLoss: 1.022703 \n",
            "Train Epoch: 21 [20/245] \tLoss: 1.216331 \n",
            "Train Epoch: 21 [40/245] \tLoss: 0.504126 \n",
            "Train Epoch: 21 [60/245] \tLoss: 0.697753 \n",
            "Train Epoch: 21 [80/245] \tLoss: 0.551770 \n",
            "Train Epoch: 21 [100/245] \tLoss: 0.548066 \n",
            "Train Epoch: 21 [120/245] \tLoss: 0.563138 \n",
            "Train Epoch: 21 [140/245] \tLoss: 0.549337 \n",
            "Train Epoch: 21 [160/245] \tLoss: 0.299306 \n",
            "Train Epoch: 21 [180/245] \tLoss: 0.427827 \n",
            "Train Epoch: 21 [200/245] \tLoss: 0.996683 \n",
            "Train Epoch: 21 [220/245] \tLoss: 0.485597 \n",
            "Train Epoch: 21 [240/245] \tLoss: 0.909791 \n",
            "\n",
            "Test set: Average loss: 0.9858, Accuracy: 506/992 (51%)\n",
            "\n",
            "Train Epoch: 22 [0/245] \tLoss: 1.024900 \n",
            "Train Epoch: 22 [20/245] \tLoss: 1.215155 \n",
            "Train Epoch: 22 [40/245] \tLoss: 0.504279 \n",
            "Train Epoch: 22 [60/245] \tLoss: 0.696929 \n",
            "Train Epoch: 22 [80/245] \tLoss: 0.552062 \n",
            "Train Epoch: 22 [100/245] \tLoss: 0.549619 \n",
            "Train Epoch: 22 [120/245] \tLoss: 0.562323 \n",
            "Train Epoch: 22 [140/245] \tLoss: 0.547749 \n",
            "Train Epoch: 22 [160/245] \tLoss: 0.296999 \n",
            "Train Epoch: 22 [180/245] \tLoss: 0.427528 \n",
            "Train Epoch: 22 [200/245] \tLoss: 0.996486 \n",
            "Train Epoch: 22 [220/245] \tLoss: 0.486812 \n",
            "Train Epoch: 22 [240/245] \tLoss: 0.907810 \n",
            "\n",
            "Test set: Average loss: 0.9890, Accuracy: 507/992 (51%)\n",
            "\n",
            "Train Epoch: 23 [0/245] \tLoss: 1.026712 \n",
            "Train Epoch: 23 [20/245] \tLoss: 1.214103 \n",
            "Train Epoch: 23 [40/245] \tLoss: 0.504345 \n",
            "Train Epoch: 23 [60/245] \tLoss: 0.696161 \n",
            "Train Epoch: 23 [80/245] \tLoss: 0.552310 \n",
            "Train Epoch: 23 [100/245] \tLoss: 0.551076 \n",
            "Train Epoch: 23 [120/245] \tLoss: 0.561615 \n",
            "Train Epoch: 23 [140/245] \tLoss: 0.546402 \n",
            "Train Epoch: 23 [160/245] \tLoss: 0.294952 \n",
            "Train Epoch: 23 [180/245] \tLoss: 0.427300 \n",
            "Train Epoch: 23 [200/245] \tLoss: 0.996349 \n",
            "Train Epoch: 23 [220/245] \tLoss: 0.487968 \n",
            "Train Epoch: 23 [240/245] \tLoss: 0.906005 \n",
            "\n",
            "Test set: Average loss: 0.9918, Accuracy: 506/992 (51%)\n",
            "\n",
            "Train Epoch: 24 [0/245] \tLoss: 1.028215 \n",
            "Train Epoch: 24 [20/245] \tLoss: 1.213149 \n",
            "Train Epoch: 24 [40/245] \tLoss: 0.504345 \n",
            "Train Epoch: 24 [60/245] \tLoss: 0.695445 \n",
            "Train Epoch: 24 [80/245] \tLoss: 0.552517 \n",
            "Train Epoch: 24 [100/245] \tLoss: 0.552437 \n",
            "Train Epoch: 24 [120/245] \tLoss: 0.560999 \n",
            "Train Epoch: 24 [140/245] \tLoss: 0.545256 \n",
            "Train Epoch: 24 [160/245] \tLoss: 0.293133 \n",
            "Train Epoch: 24 [180/245] \tLoss: 0.427129 \n",
            "Train Epoch: 24 [200/245] \tLoss: 0.996264 \n",
            "Train Epoch: 24 [220/245] \tLoss: 0.489068 \n",
            "Train Epoch: 24 [240/245] \tLoss: 0.904366 \n",
            "\n",
            "Test set: Average loss: 0.9942, Accuracy: 505/992 (51%)\n",
            "\n",
            "Train Epoch: 25 [0/245] \tLoss: 1.029472 \n",
            "Train Epoch: 25 [20/245] \tLoss: 1.212273 \n",
            "Train Epoch: 25 [40/245] \tLoss: 0.504293 \n",
            "Train Epoch: 25 [60/245] \tLoss: 0.694778 \n",
            "Train Epoch: 25 [80/245] \tLoss: 0.552690 \n",
            "Train Epoch: 25 [100/245] \tLoss: 0.553703 \n",
            "Train Epoch: 25 [120/245] \tLoss: 0.560462 \n",
            "Train Epoch: 25 [140/245] \tLoss: 0.544279 \n",
            "Train Epoch: 25 [160/245] \tLoss: 0.291516 \n",
            "Train Epoch: 25 [180/245] \tLoss: 0.427005 \n",
            "Train Epoch: 25 [200/245] \tLoss: 0.996222 \n",
            "Train Epoch: 25 [220/245] \tLoss: 0.490115 \n",
            "Train Epoch: 25 [240/245] \tLoss: 0.902882 \n",
            "\n",
            "Test set: Average loss: 0.9963, Accuracy: 505/992 (51%)\n",
            "\n",
            "Train Epoch: 26 [0/245] \tLoss: 1.030529 \n",
            "Train Epoch: 26 [20/245] \tLoss: 1.211461 \n",
            "Train Epoch: 26 [40/245] \tLoss: 0.504202 \n",
            "Train Epoch: 26 [60/245] \tLoss: 0.694155 \n",
            "Train Epoch: 26 [80/245] \tLoss: 0.552832 \n",
            "Train Epoch: 26 [100/245] \tLoss: 0.554878 \n",
            "Train Epoch: 26 [120/245] \tLoss: 0.559996 \n",
            "Train Epoch: 26 [140/245] \tLoss: 0.543445 \n",
            "Train Epoch: 26 [160/245] \tLoss: 0.290075 \n",
            "Train Epoch: 26 [180/245] \tLoss: 0.426920 \n",
            "Train Epoch: 26 [200/245] \tLoss: 0.996217 \n",
            "Train Epoch: 26 [220/245] \tLoss: 0.491110 \n",
            "Train Epoch: 26 [240/245] \tLoss: 0.901539 \n",
            "\n",
            "Test set: Average loss: 0.9982, Accuracy: 504/992 (51%)\n",
            "\n",
            "Train Epoch: 27 [0/245] \tLoss: 1.031424 \n",
            "Train Epoch: 27 [20/245] \tLoss: 1.210703 \n",
            "Train Epoch: 27 [40/245] \tLoss: 0.504081 \n",
            "Train Epoch: 27 [60/245] \tLoss: 0.693573 \n",
            "Train Epoch: 27 [80/245] \tLoss: 0.552946 \n",
            "Train Epoch: 27 [100/245] \tLoss: 0.555966 \n",
            "Train Epoch: 27 [120/245] \tLoss: 0.559590 \n",
            "Train Epoch: 27 [140/245] \tLoss: 0.542729 \n",
            "Train Epoch: 27 [160/245] \tLoss: 0.288791 \n",
            "Train Epoch: 27 [180/245] \tLoss: 0.426865 \n",
            "Train Epoch: 27 [200/245] \tLoss: 0.996244 \n",
            "Train Epoch: 27 [220/245] \tLoss: 0.492056 \n",
            "Train Epoch: 27 [240/245] \tLoss: 0.900329 \n",
            "\n",
            "Test set: Average loss: 0.9998, Accuracy: 503/992 (51%)\n",
            "\n",
            "Train Epoch: 28 [0/245] \tLoss: 1.032185 \n",
            "Train Epoch: 28 [20/245] \tLoss: 1.209989 \n",
            "Train Epoch: 28 [40/245] \tLoss: 0.503938 \n",
            "Train Epoch: 28 [60/245] \tLoss: 0.693029 \n",
            "Train Epoch: 28 [80/245] \tLoss: 0.553038 \n",
            "Train Epoch: 28 [100/245] \tLoss: 0.556971 \n",
            "Train Epoch: 28 [120/245] \tLoss: 0.559237 \n",
            "Train Epoch: 28 [140/245] \tLoss: 0.542114 \n",
            "Train Epoch: 28 [160/245] \tLoss: 0.287645 \n",
            "Train Epoch: 28 [180/245] \tLoss: 0.426835 \n",
            "Train Epoch: 28 [200/245] \tLoss: 0.996297 \n",
            "Train Epoch: 28 [220/245] \tLoss: 0.492953 \n",
            "Train Epoch: 28 [240/245] \tLoss: 0.899238 \n",
            "\n",
            "Test set: Average loss: 1.0013, Accuracy: 503/992 (51%)\n",
            "\n",
            "Train Epoch: 29 [0/245] \tLoss: 1.032835 \n",
            "Train Epoch: 29 [20/245] \tLoss: 1.209313 \n",
            "Train Epoch: 29 [40/245] \tLoss: 0.503777 \n",
            "Train Epoch: 29 [60/245] \tLoss: 0.692518 \n",
            "Train Epoch: 29 [80/245] \tLoss: 0.553109 \n",
            "Train Epoch: 29 [100/245] \tLoss: 0.557898 \n",
            "Train Epoch: 29 [120/245] \tLoss: 0.558930 \n",
            "Train Epoch: 29 [140/245] \tLoss: 0.541585 \n",
            "Train Epoch: 29 [160/245] \tLoss: 0.286621 \n",
            "Train Epoch: 29 [180/245] \tLoss: 0.426825 \n",
            "Train Epoch: 29 [200/245] \tLoss: 0.996370 \n",
            "Train Epoch: 29 [220/245] \tLoss: 0.493805 \n",
            "Train Epoch: 29 [240/245] \tLoss: 0.898257 \n",
            "\n",
            "Test set: Average loss: 1.0026, Accuracy: 502/992 (51%)\n",
            "\n",
            "Train Epoch: 30 [0/245] \tLoss: 1.033390 \n",
            "Train Epoch: 30 [20/245] \tLoss: 1.208674 \n",
            "Train Epoch: 30 [40/245] \tLoss: 0.503605 \n",
            "Train Epoch: 30 [60/245] \tLoss: 0.692038 \n",
            "Train Epoch: 30 [80/245] \tLoss: 0.553163 \n",
            "Train Epoch: 30 [100/245] \tLoss: 0.558751 \n",
            "Train Epoch: 30 [120/245] \tLoss: 0.558663 \n",
            "Train Epoch: 30 [140/245] \tLoss: 0.541130 \n",
            "Train Epoch: 30 [160/245] \tLoss: 0.285704 \n",
            "Train Epoch: 30 [180/245] \tLoss: 0.426830 \n",
            "Train Epoch: 30 [200/245] \tLoss: 0.996461 \n",
            "Train Epoch: 30 [220/245] \tLoss: 0.494612 \n",
            "Train Epoch: 30 [240/245] \tLoss: 0.897375 \n",
            "\n",
            "Test set: Average loss: 1.0038, Accuracy: 502/992 (51%)\n",
            "\n",
            "Train Epoch: 31 [0/245] \tLoss: 1.033866 \n",
            "Train Epoch: 31 [20/245] \tLoss: 1.208064 \n",
            "Train Epoch: 31 [40/245] \tLoss: 0.503424 \n",
            "Train Epoch: 31 [60/245] \tLoss: 0.691585 \n",
            "Train Epoch: 31 [80/245] \tLoss: 0.553203 \n",
            "Train Epoch: 31 [100/245] \tLoss: 0.559537 \n",
            "Train Epoch: 31 [120/245] \tLoss: 0.558431 \n",
            "Train Epoch: 31 [140/245] \tLoss: 0.540737 \n",
            "Train Epoch: 31 [160/245] \tLoss: 0.284884 \n",
            "Train Epoch: 31 [180/245] \tLoss: 0.426847 \n",
            "Train Epoch: 31 [200/245] \tLoss: 0.996565 \n",
            "Train Epoch: 31 [220/245] \tLoss: 0.495376 \n",
            "Train Epoch: 31 [240/245] \tLoss: 0.896584 \n",
            "\n",
            "Test set: Average loss: 1.0048, Accuracy: 501/992 (51%)\n",
            "\n",
            "Train Epoch: 32 [0/245] \tLoss: 1.034273 \n",
            "Train Epoch: 32 [20/245] \tLoss: 1.207481 \n",
            "Train Epoch: 32 [40/245] \tLoss: 0.503236 \n",
            "Train Epoch: 32 [60/245] \tLoss: 0.691158 \n",
            "Train Epoch: 32 [80/245] \tLoss: 0.553231 \n",
            "Train Epoch: 32 [100/245] \tLoss: 0.560259 \n",
            "Train Epoch: 32 [120/245] \tLoss: 0.558230 \n",
            "Train Epoch: 32 [140/245] \tLoss: 0.540398 \n",
            "Train Epoch: 32 [160/245] \tLoss: 0.284148 \n",
            "Train Epoch: 32 [180/245] \tLoss: 0.426873 \n",
            "Train Epoch: 32 [200/245] \tLoss: 0.996680 \n",
            "Train Epoch: 32 [220/245] \tLoss: 0.496100 \n",
            "Train Epoch: 32 [240/245] \tLoss: 0.895876 \n",
            "\n",
            "Test set: Average loss: 1.0058, Accuracy: 501/992 (51%)\n",
            "\n",
            "Train Epoch: 33 [0/245] \tLoss: 1.034624 \n",
            "Train Epoch: 33 [20/245] \tLoss: 1.206924 \n",
            "Train Epoch: 33 [40/245] \tLoss: 0.503046 \n",
            "Train Epoch: 33 [60/245] \tLoss: 0.690755 \n",
            "Train Epoch: 33 [80/245] \tLoss: 0.553248 \n",
            "Train Epoch: 33 [100/245] \tLoss: 0.560921 \n",
            "Train Epoch: 33 [120/245] \tLoss: 0.558056 \n",
            "Train Epoch: 33 [140/245] \tLoss: 0.540104 \n",
            "Train Epoch: 33 [160/245] \tLoss: 0.283488 \n",
            "Train Epoch: 33 [180/245] \tLoss: 0.426905 \n",
            "Train Epoch: 33 [200/245] \tLoss: 0.996803 \n",
            "Train Epoch: 33 [220/245] \tLoss: 0.496785 \n",
            "Train Epoch: 33 [240/245] \tLoss: 0.895242 \n",
            "\n",
            "Test set: Average loss: 1.0066, Accuracy: 503/992 (51%)\n",
            "\n",
            "Train Epoch: 34 [0/245] \tLoss: 1.034920 \n",
            "Train Epoch: 34 [20/245] \tLoss: 1.206391 \n",
            "Train Epoch: 34 [40/245] \tLoss: 0.502854 \n",
            "Train Epoch: 34 [60/245] \tLoss: 0.690373 \n",
            "Train Epoch: 34 [80/245] \tLoss: 0.553256 \n",
            "Train Epoch: 34 [100/245] \tLoss: 0.561529 \n",
            "Train Epoch: 34 [120/245] \tLoss: 0.557905 \n",
            "Train Epoch: 34 [140/245] \tLoss: 0.539850 \n",
            "Train Epoch: 34 [160/245] \tLoss: 0.282894 \n",
            "Train Epoch: 34 [180/245] \tLoss: 0.426942 \n",
            "Train Epoch: 34 [200/245] \tLoss: 0.996931 \n",
            "Train Epoch: 34 [220/245] \tLoss: 0.497432 \n",
            "Train Epoch: 34 [240/245] \tLoss: 0.894675 \n",
            "\n",
            "Test set: Average loss: 1.0074, Accuracy: 503/992 (51%)\n",
            "\n",
            "Train Epoch: 35 [0/245] \tLoss: 1.035172 \n",
            "Train Epoch: 35 [20/245] \tLoss: 1.205880 \n",
            "Train Epoch: 35 [40/245] \tLoss: 0.502662 \n",
            "Train Epoch: 35 [60/245] \tLoss: 0.690010 \n",
            "Train Epoch: 35 [80/245] \tLoss: 0.553258 \n",
            "Train Epoch: 35 [100/245] \tLoss: 0.562088 \n",
            "Train Epoch: 35 [120/245] \tLoss: 0.557775 \n",
            "Train Epoch: 35 [140/245] \tLoss: 0.539628 \n",
            "Train Epoch: 35 [160/245] \tLoss: 0.282361 \n",
            "Train Epoch: 35 [180/245] \tLoss: 0.426983 \n",
            "Train Epoch: 35 [200/245] \tLoss: 0.997062 \n",
            "Train Epoch: 35 [220/245] \tLoss: 0.498043 \n",
            "Train Epoch: 35 [240/245] \tLoss: 0.894170 \n",
            "\n",
            "Test set: Average loss: 1.0080, Accuracy: 502/992 (51%)\n",
            "\n",
            "Train Epoch: 36 [0/245] \tLoss: 1.035386 \n",
            "Train Epoch: 36 [20/245] \tLoss: 1.205389 \n",
            "Train Epoch: 36 [40/245] \tLoss: 0.502470 \n",
            "Train Epoch: 36 [60/245] \tLoss: 0.689666 \n",
            "Train Epoch: 36 [80/245] \tLoss: 0.553254 \n",
            "Train Epoch: 36 [100/245] \tLoss: 0.562599 \n",
            "Train Epoch: 36 [120/245] \tLoss: 0.557663 \n",
            "Train Epoch: 36 [140/245] \tLoss: 0.539436 \n",
            "Train Epoch: 36 [160/245] \tLoss: 0.281881 \n",
            "Train Epoch: 36 [180/245] \tLoss: 0.427026 \n",
            "Train Epoch: 36 [200/245] \tLoss: 0.997197 \n",
            "Train Epoch: 36 [220/245] \tLoss: 0.498621 \n",
            "Train Epoch: 36 [240/245] \tLoss: 0.893721 \n",
            "\n",
            "Test set: Average loss: 1.0086, Accuracy: 501/992 (51%)\n",
            "\n",
            "Train Epoch: 37 [0/245] \tLoss: 1.035565 \n",
            "Train Epoch: 37 [20/245] \tLoss: 1.204919 \n",
            "Train Epoch: 37 [40/245] \tLoss: 0.502281 \n",
            "Train Epoch: 37 [60/245] \tLoss: 0.689339 \n",
            "Train Epoch: 37 [80/245] \tLoss: 0.553246 \n",
            "Train Epoch: 37 [100/245] \tLoss: 0.563068 \n",
            "Train Epoch: 37 [120/245] \tLoss: 0.557567 \n",
            "Train Epoch: 37 [140/245] \tLoss: 0.539269 \n",
            "Train Epoch: 37 [160/245] \tLoss: 0.281449 \n",
            "Train Epoch: 37 [180/245] \tLoss: 0.427070 \n",
            "Train Epoch: 37 [200/245] \tLoss: 0.997331 \n",
            "Train Epoch: 37 [220/245] \tLoss: 0.499167 \n",
            "Train Epoch: 37 [240/245] \tLoss: 0.893321 \n",
            "\n",
            "Test set: Average loss: 1.0092, Accuracy: 501/992 (51%)\n",
            "\n",
            "Train Epoch: 38 [0/245] \tLoss: 1.035712 \n",
            "Train Epoch: 38 [20/245] \tLoss: 1.204468 \n",
            "Train Epoch: 38 [40/245] \tLoss: 0.502095 \n",
            "Train Epoch: 38 [60/245] \tLoss: 0.689027 \n",
            "Train Epoch: 38 [80/245] \tLoss: 0.553235 \n",
            "Train Epoch: 38 [100/245] \tLoss: 0.563498 \n",
            "Train Epoch: 38 [120/245] \tLoss: 0.557484 \n",
            "Train Epoch: 38 [140/245] \tLoss: 0.539123 \n",
            "Train Epoch: 38 [160/245] \tLoss: 0.281060 \n",
            "Train Epoch: 38 [180/245] \tLoss: 0.427114 \n",
            "Train Epoch: 38 [200/245] \tLoss: 0.997465 \n",
            "Train Epoch: 38 [220/245] \tLoss: 0.499682 \n",
            "Train Epoch: 38 [240/245] \tLoss: 0.892967 \n",
            "\n",
            "Test set: Average loss: 1.0097, Accuracy: 501/992 (51%)\n",
            "\n",
            "Train Epoch: 39 [0/245] \tLoss: 1.035836 \n",
            "Train Epoch: 39 [20/245] \tLoss: 1.204033 \n",
            "Train Epoch: 39 [40/245] \tLoss: 0.501911 \n",
            "Train Epoch: 39 [60/245] \tLoss: 0.688729 \n",
            "Train Epoch: 39 [80/245] \tLoss: 0.553220 \n",
            "Train Epoch: 39 [100/245] \tLoss: 0.563892 \n",
            "Train Epoch: 39 [120/245] \tLoss: 0.557414 \n",
            "Train Epoch: 39 [140/245] \tLoss: 0.538996 \n",
            "Train Epoch: 39 [160/245] \tLoss: 0.280708 \n",
            "Train Epoch: 39 [180/245] \tLoss: 0.427158 \n",
            "Train Epoch: 39 [200/245] \tLoss: 0.997599 \n",
            "Train Epoch: 39 [220/245] \tLoss: 0.500169 \n",
            "Train Epoch: 39 [240/245] \tLoss: 0.892655 \n",
            "\n",
            "Test set: Average loss: 1.0101, Accuracy: 501/992 (51%)\n",
            "\n",
            "Train Epoch: 40 [0/245] \tLoss: 1.035932 \n",
            "Train Epoch: 40 [20/245] \tLoss: 1.203618 \n",
            "Train Epoch: 40 [40/245] \tLoss: 0.501731 \n",
            "Train Epoch: 40 [60/245] \tLoss: 0.688445 \n",
            "Train Epoch: 40 [80/245] \tLoss: 0.553203 \n",
            "Train Epoch: 40 [100/245] \tLoss: 0.564253 \n",
            "Train Epoch: 40 [120/245] \tLoss: 0.557355 \n",
            "Train Epoch: 40 [140/245] \tLoss: 0.538884 \n",
            "Train Epoch: 40 [160/245] \tLoss: 0.280391 \n",
            "Train Epoch: 40 [180/245] \tLoss: 0.427201 \n",
            "Train Epoch: 40 [200/245] \tLoss: 0.997731 \n",
            "Train Epoch: 40 [220/245] \tLoss: 0.500628 \n",
            "Train Epoch: 40 [240/245] \tLoss: 0.892378 \n",
            "\n",
            "Test set: Average loss: 1.0105, Accuracy: 501/992 (51%)\n",
            "\n",
            "Train Epoch: 41 [0/245] \tLoss: 1.036008 \n",
            "Train Epoch: 41 [20/245] \tLoss: 1.203218 \n",
            "Train Epoch: 41 [40/245] \tLoss: 0.501556 \n",
            "Train Epoch: 41 [60/245] \tLoss: 0.688173 \n",
            "Train Epoch: 41 [80/245] \tLoss: 0.553185 \n",
            "Train Epoch: 41 [100/245] \tLoss: 0.564584 \n",
            "Train Epoch: 41 [120/245] \tLoss: 0.557305 \n",
            "Train Epoch: 41 [140/245] \tLoss: 0.538785 \n",
            "Train Epoch: 41 [160/245] \tLoss: 0.280105 \n",
            "Train Epoch: 41 [180/245] \tLoss: 0.427242 \n",
            "Train Epoch: 41 [200/245] \tLoss: 0.997860 \n",
            "Train Epoch: 41 [220/245] \tLoss: 0.501062 \n",
            "Train Epoch: 41 [240/245] \tLoss: 0.892136 \n",
            "\n",
            "Test set: Average loss: 1.0109, Accuracy: 501/992 (51%)\n",
            "\n",
            "Train Epoch: 42 [0/245] \tLoss: 1.036065 \n",
            "Train Epoch: 42 [20/245] \tLoss: 1.202834 \n",
            "Train Epoch: 42 [40/245] \tLoss: 0.501384 \n",
            "Train Epoch: 42 [60/245] \tLoss: 0.687913 \n",
            "Train Epoch: 42 [80/245] \tLoss: 0.553166 \n",
            "Train Epoch: 42 [100/245] \tLoss: 0.564887 \n",
            "Train Epoch: 42 [120/245] \tLoss: 0.557264 \n",
            "Train Epoch: 42 [140/245] \tLoss: 0.538698 \n",
            "Train Epoch: 42 [160/245] \tLoss: 0.279846 \n",
            "Train Epoch: 42 [180/245] \tLoss: 0.427282 \n",
            "Train Epoch: 42 [200/245] \tLoss: 0.997987 \n",
            "Train Epoch: 42 [220/245] \tLoss: 0.501471 \n",
            "Train Epoch: 42 [240/245] \tLoss: 0.891924 \n",
            "\n",
            "Test set: Average loss: 1.0112, Accuracy: 501/992 (51%)\n",
            "\n",
            "Train Epoch: 43 [0/245] \tLoss: 1.036106 \n",
            "Train Epoch: 43 [20/245] \tLoss: 1.202464 \n",
            "Train Epoch: 43 [40/245] \tLoss: 0.501218 \n",
            "Train Epoch: 43 [60/245] \tLoss: 0.687663 \n",
            "Train Epoch: 43 [80/245] \tLoss: 0.553147 \n",
            "Train Epoch: 43 [100/245] \tLoss: 0.565165 \n",
            "Train Epoch: 43 [120/245] \tLoss: 0.557230 \n",
            "Train Epoch: 43 [140/245] \tLoss: 0.538620 \n",
            "Train Epoch: 43 [160/245] \tLoss: 0.279611 \n",
            "Train Epoch: 43 [180/245] \tLoss: 0.427320 \n",
            "Train Epoch: 43 [200/245] \tLoss: 0.998110 \n",
            "Train Epoch: 43 [220/245] \tLoss: 0.501857 \n",
            "Train Epoch: 43 [240/245] \tLoss: 0.891739 \n",
            "\n",
            "Test set: Average loss: 1.0115, Accuracy: 501/992 (51%)\n",
            "\n",
            "Train Epoch: 44 [0/245] \tLoss: 1.036130 \n",
            "Train Epoch: 44 [20/245] \tLoss: 1.202109 \n",
            "Train Epoch: 44 [40/245] \tLoss: 0.501055 \n",
            "Train Epoch: 44 [60/245] \tLoss: 0.687423 \n",
            "Train Epoch: 44 [80/245] \tLoss: 0.553127 \n",
            "Train Epoch: 44 [100/245] \tLoss: 0.565420 \n",
            "Train Epoch: 44 [120/245] \tLoss: 0.557203 \n",
            "Train Epoch: 44 [140/245] \tLoss: 0.538551 \n",
            "Train Epoch: 44 [160/245] \tLoss: 0.279400 \n",
            "Train Epoch: 44 [180/245] \tLoss: 0.427357 \n",
            "Train Epoch: 44 [200/245] \tLoss: 0.998230 \n",
            "Train Epoch: 44 [220/245] \tLoss: 0.502222 \n",
            "Train Epoch: 44 [240/245] \tLoss: 0.891579 \n",
            "\n",
            "Test set: Average loss: 1.0117, Accuracy: 501/992 (51%)\n",
            "\n",
            "Train Epoch: 45 [0/245] \tLoss: 1.036139 \n",
            "Train Epoch: 45 [20/245] \tLoss: 1.201769 \n",
            "Train Epoch: 45 [40/245] \tLoss: 0.500897 \n",
            "Train Epoch: 45 [60/245] \tLoss: 0.687194 \n",
            "Train Epoch: 45 [80/245] \tLoss: 0.553107 \n",
            "Train Epoch: 45 [100/245] \tLoss: 0.565653 \n",
            "Train Epoch: 45 [120/245] \tLoss: 0.557182 \n",
            "Train Epoch: 45 [140/245] \tLoss: 0.538489 \n",
            "Train Epoch: 45 [160/245] \tLoss: 0.279207 \n",
            "Train Epoch: 45 [180/245] \tLoss: 0.427392 \n",
            "Train Epoch: 45 [200/245] \tLoss: 0.998348 \n",
            "Train Epoch: 45 [220/245] \tLoss: 0.502566 \n",
            "Train Epoch: 45 [240/245] \tLoss: 0.891441 \n",
            "\n",
            "Test set: Average loss: 1.0119, Accuracy: 501/992 (51%)\n",
            "\n",
            "Train Epoch: 46 [0/245] \tLoss: 1.036138 \n",
            "Train Epoch: 46 [20/245] \tLoss: 1.201442 \n",
            "Train Epoch: 46 [40/245] \tLoss: 0.500744 \n",
            "Train Epoch: 46 [60/245] \tLoss: 0.686972 \n",
            "Train Epoch: 46 [80/245] \tLoss: 0.553087 \n",
            "Train Epoch: 46 [100/245] \tLoss: 0.565868 \n",
            "Train Epoch: 46 [120/245] \tLoss: 0.557166 \n",
            "Train Epoch: 46 [140/245] \tLoss: 0.538434 \n",
            "Train Epoch: 46 [160/245] \tLoss: 0.279033 \n",
            "Train Epoch: 46 [180/245] \tLoss: 0.427424 \n",
            "Train Epoch: 46 [200/245] \tLoss: 0.998460 \n",
            "Train Epoch: 46 [220/245] \tLoss: 0.502891 \n",
            "Train Epoch: 46 [240/245] \tLoss: 0.891323 \n",
            "\n",
            "Test set: Average loss: 1.0121, Accuracy: 501/992 (51%)\n",
            "\n",
            "Train Epoch: 47 [0/245] \tLoss: 1.036125 \n",
            "Train Epoch: 47 [20/245] \tLoss: 1.201127 \n",
            "Train Epoch: 47 [40/245] \tLoss: 0.500596 \n",
            "Train Epoch: 47 [60/245] \tLoss: 0.686759 \n",
            "Train Epoch: 47 [80/245] \tLoss: 0.553068 \n",
            "Train Epoch: 47 [100/245] \tLoss: 0.566064 \n",
            "Train Epoch: 47 [120/245] \tLoss: 0.557154 \n",
            "Train Epoch: 47 [140/245] \tLoss: 0.538383 \n",
            "Train Epoch: 47 [160/245] \tLoss: 0.278875 \n",
            "Train Epoch: 47 [180/245] \tLoss: 0.427455 \n",
            "Train Epoch: 47 [200/245] \tLoss: 0.998570 \n",
            "Train Epoch: 47 [220/245] \tLoss: 0.503198 \n",
            "Train Epoch: 47 [240/245] \tLoss: 0.891223 \n",
            "\n",
            "Test set: Average loss: 1.0123, Accuracy: 502/992 (51%)\n",
            "\n",
            "Train Epoch: 48 [0/245] \tLoss: 1.036101 \n",
            "Train Epoch: 48 [20/245] \tLoss: 1.200825 \n",
            "Train Epoch: 48 [40/245] \tLoss: 0.500451 \n",
            "Train Epoch: 48 [60/245] \tLoss: 0.686553 \n",
            "Train Epoch: 48 [80/245] \tLoss: 0.553050 \n",
            "Train Epoch: 48 [100/245] \tLoss: 0.566244 \n",
            "Train Epoch: 48 [120/245] \tLoss: 0.557147 \n",
            "Train Epoch: 48 [140/245] \tLoss: 0.538338 \n",
            "Train Epoch: 48 [160/245] \tLoss: 0.278732 \n",
            "Train Epoch: 48 [180/245] \tLoss: 0.427484 \n",
            "Train Epoch: 48 [200/245] \tLoss: 0.998675 \n",
            "Train Epoch: 48 [220/245] \tLoss: 0.503489 \n",
            "Train Epoch: 48 [240/245] \tLoss: 0.891140 \n",
            "\n",
            "Test set: Average loss: 1.0125, Accuracy: 502/992 (51%)\n",
            "\n",
            "Train Epoch: 49 [0/245] \tLoss: 1.036070 \n",
            "Train Epoch: 49 [20/245] \tLoss: 1.200535 \n",
            "Train Epoch: 49 [40/245] \tLoss: 0.500312 \n",
            "Train Epoch: 49 [60/245] \tLoss: 0.686355 \n",
            "Train Epoch: 49 [80/245] \tLoss: 0.553032 \n",
            "Train Epoch: 49 [100/245] \tLoss: 0.566410 \n",
            "Train Epoch: 49 [120/245] \tLoss: 0.557143 \n",
            "Train Epoch: 49 [140/245] \tLoss: 0.538295 \n",
            "Train Epoch: 49 [160/245] \tLoss: 0.278602 \n",
            "Train Epoch: 49 [180/245] \tLoss: 0.427510 \n",
            "Train Epoch: 49 [200/245] \tLoss: 0.998778 \n",
            "Train Epoch: 49 [220/245] \tLoss: 0.503763 \n",
            "Train Epoch: 49 [240/245] \tLoss: 0.891071 \n",
            "\n",
            "Test set: Average loss: 1.0126, Accuracy: 502/992 (51%)\n",
            "\n",
            "Train Epoch: 50 [0/245] \tLoss: 1.036031 \n",
            "Train Epoch: 50 [20/245] \tLoss: 1.200255 \n",
            "Train Epoch: 50 [40/245] \tLoss: 0.500177 \n",
            "Train Epoch: 50 [60/245] \tLoss: 0.686164 \n",
            "Train Epoch: 50 [80/245] \tLoss: 0.553014 \n",
            "Train Epoch: 50 [100/245] \tLoss: 0.566562 \n",
            "Train Epoch: 50 [120/245] \tLoss: 0.557143 \n",
            "Train Epoch: 50 [140/245] \tLoss: 0.538255 \n",
            "Train Epoch: 50 [160/245] \tLoss: 0.278484 \n",
            "Train Epoch: 50 [180/245] \tLoss: 0.427535 \n",
            "Train Epoch: 50 [200/245] \tLoss: 0.998876 \n",
            "Train Epoch: 50 [220/245] \tLoss: 0.504022 \n",
            "Train Epoch: 50 [240/245] \tLoss: 0.891015 \n",
            "\n",
            "Test set: Average loss: 1.0128, Accuracy: 501/992 (51%)\n",
            "\n",
            "Train Epoch: 51 [0/245] \tLoss: 1.035985 \n",
            "Train Epoch: 51 [20/245] \tLoss: 1.199987 \n",
            "Train Epoch: 51 [40/245] \tLoss: 0.500046 \n",
            "Train Epoch: 51 [60/245] \tLoss: 0.685979 \n",
            "Train Epoch: 51 [80/245] \tLoss: 0.552998 \n",
            "Train Epoch: 51 [100/245] \tLoss: 0.566702 \n",
            "Train Epoch: 51 [120/245] \tLoss: 0.557145 \n",
            "Train Epoch: 51 [140/245] \tLoss: 0.538219 \n",
            "Train Epoch: 51 [160/245] \tLoss: 0.278376 \n",
            "Train Epoch: 51 [180/245] \tLoss: 0.427558 \n",
            "Train Epoch: 51 [200/245] \tLoss: 0.998971 \n",
            "Train Epoch: 51 [220/245] \tLoss: 0.504267 \n",
            "Train Epoch: 51 [240/245] \tLoss: 0.890971 \n",
            "\n",
            "Test set: Average loss: 1.0129, Accuracy: 501/992 (51%)\n",
            "\n",
            "Train Epoch: 52 [0/245] \tLoss: 1.035931 \n",
            "Train Epoch: 52 [20/245] \tLoss: 1.199728 \n",
            "Train Epoch: 52 [40/245] \tLoss: 0.499919 \n",
            "Train Epoch: 52 [60/245] \tLoss: 0.685800 \n",
            "Train Epoch: 52 [80/245] \tLoss: 0.552982 \n",
            "Train Epoch: 52 [100/245] \tLoss: 0.566830 \n",
            "Train Epoch: 52 [120/245] \tLoss: 0.557150 \n",
            "Train Epoch: 52 [140/245] \tLoss: 0.538185 \n",
            "Train Epoch: 52 [160/245] \tLoss: 0.278278 \n",
            "Train Epoch: 52 [180/245] \tLoss: 0.427579 \n",
            "Train Epoch: 52 [200/245] \tLoss: 0.999062 \n",
            "Train Epoch: 52 [220/245] \tLoss: 0.504499 \n",
            "Train Epoch: 52 [240/245] \tLoss: 0.890938 \n",
            "\n",
            "Test set: Average loss: 1.0130, Accuracy: 501/992 (51%)\n",
            "\n",
            "Train Epoch: 53 [0/245] \tLoss: 1.035873 \n",
            "Train Epoch: 53 [20/245] \tLoss: 1.199479 \n",
            "Train Epoch: 53 [40/245] \tLoss: 0.499797 \n",
            "Train Epoch: 53 [60/245] \tLoss: 0.685627 \n",
            "Train Epoch: 53 [80/245] \tLoss: 0.552967 \n",
            "Train Epoch: 53 [100/245] \tLoss: 0.566948 \n",
            "Train Epoch: 53 [120/245] \tLoss: 0.557157 \n",
            "Train Epoch: 53 [140/245] \tLoss: 0.538151 \n",
            "Train Epoch: 53 [160/245] \tLoss: 0.278189 \n",
            "Train Epoch: 53 [180/245] \tLoss: 0.427598 \n",
            "Train Epoch: 53 [200/245] \tLoss: 0.999150 \n",
            "Train Epoch: 53 [220/245] \tLoss: 0.504719 \n",
            "Train Epoch: 53 [240/245] \tLoss: 0.890914 \n",
            "\n",
            "Test set: Average loss: 1.0131, Accuracy: 500/992 (50%)\n",
            "\n",
            "Train Epoch: 54 [0/245] \tLoss: 1.035811 \n",
            "Train Epoch: 54 [20/245] \tLoss: 1.199239 \n",
            "Train Epoch: 54 [40/245] \tLoss: 0.499679 \n",
            "Train Epoch: 54 [60/245] \tLoss: 0.685459 \n",
            "Train Epoch: 54 [80/245] \tLoss: 0.552953 \n",
            "Train Epoch: 54 [100/245] \tLoss: 0.567057 \n",
            "Train Epoch: 54 [120/245] \tLoss: 0.557167 \n",
            "Train Epoch: 54 [140/245] \tLoss: 0.538120 \n",
            "Train Epoch: 54 [160/245] \tLoss: 0.278109 \n",
            "Train Epoch: 54 [180/245] \tLoss: 0.427616 \n",
            "Train Epoch: 54 [200/245] \tLoss: 0.999235 \n",
            "Train Epoch: 54 [220/245] \tLoss: 0.504927 \n",
            "Train Epoch: 54 [240/245] \tLoss: 0.890898 \n",
            "\n",
            "Test set: Average loss: 1.0131, Accuracy: 500/992 (50%)\n",
            "\n",
            "Train Epoch: 55 [0/245] \tLoss: 1.035745 \n",
            "Train Epoch: 55 [20/245] \tLoss: 1.199007 \n",
            "Train Epoch: 55 [40/245] \tLoss: 0.499564 \n",
            "Train Epoch: 55 [60/245] \tLoss: 0.685296 \n",
            "Train Epoch: 55 [80/245] \tLoss: 0.552939 \n",
            "Train Epoch: 55 [100/245] \tLoss: 0.567157 \n",
            "Train Epoch: 55 [120/245] \tLoss: 0.557178 \n",
            "Train Epoch: 55 [140/245] \tLoss: 0.538090 \n",
            "Train Epoch: 55 [160/245] \tLoss: 0.278035 \n",
            "Train Epoch: 55 [180/245] \tLoss: 0.427632 \n",
            "Train Epoch: 55 [200/245] \tLoss: 0.999317 \n",
            "Train Epoch: 55 [220/245] \tLoss: 0.505125 \n",
            "Train Epoch: 55 [240/245] \tLoss: 0.890891 \n",
            "\n",
            "Test set: Average loss: 1.0132, Accuracy: 500/992 (50%)\n",
            "\n",
            "Train Epoch: 56 [0/245] \tLoss: 1.035675 \n",
            "Train Epoch: 56 [20/245] \tLoss: 1.198786 \n",
            "Train Epoch: 56 [40/245] \tLoss: 0.499454 \n",
            "Train Epoch: 56 [60/245] \tLoss: 0.685137 \n",
            "Train Epoch: 56 [80/245] \tLoss: 0.552927 \n",
            "Train Epoch: 56 [100/245] \tLoss: 0.567250 \n",
            "Train Epoch: 56 [120/245] \tLoss: 0.557190 \n",
            "Train Epoch: 56 [140/245] \tLoss: 0.538061 \n",
            "Train Epoch: 56 [160/245] \tLoss: 0.277968 \n",
            "Train Epoch: 56 [180/245] \tLoss: 0.427646 \n",
            "Train Epoch: 56 [200/245] \tLoss: 0.999395 \n",
            "Train Epoch: 56 [220/245] \tLoss: 0.505312 \n",
            "Train Epoch: 56 [240/245] \tLoss: 0.890890 \n",
            "\n",
            "Test set: Average loss: 1.0132, Accuracy: 500/992 (50%)\n",
            "\n",
            "Train Epoch: 57 [0/245] \tLoss: 1.035601 \n",
            "Train Epoch: 57 [20/245] \tLoss: 1.198570 \n",
            "Train Epoch: 57 [40/245] \tLoss: 0.499346 \n",
            "Train Epoch: 57 [60/245] \tLoss: 0.684983 \n",
            "Train Epoch: 57 [80/245] \tLoss: 0.552915 \n",
            "Train Epoch: 57 [100/245] \tLoss: 0.567335 \n",
            "Train Epoch: 57 [120/245] \tLoss: 0.557204 \n",
            "Train Epoch: 57 [140/245] \tLoss: 0.538033 \n",
            "Train Epoch: 57 [160/245] \tLoss: 0.277906 \n",
            "Train Epoch: 57 [180/245] \tLoss: 0.427659 \n",
            "Train Epoch: 57 [200/245] \tLoss: 0.999470 \n",
            "Train Epoch: 57 [220/245] \tLoss: 0.505489 \n",
            "Train Epoch: 57 [240/245] \tLoss: 0.890895 \n",
            "\n",
            "Test set: Average loss: 1.0133, Accuracy: 500/992 (50%)\n",
            "\n",
            "Train Epoch: 58 [0/245] \tLoss: 1.035523 \n",
            "Train Epoch: 58 [20/245] \tLoss: 1.198364 \n",
            "Train Epoch: 58 [40/245] \tLoss: 0.499243 \n",
            "Train Epoch: 58 [60/245] \tLoss: 0.684834 \n",
            "Train Epoch: 58 [80/245] \tLoss: 0.552904 \n",
            "Train Epoch: 58 [100/245] \tLoss: 0.567413 \n",
            "Train Epoch: 58 [120/245] \tLoss: 0.557219 \n",
            "Train Epoch: 58 [140/245] \tLoss: 0.538005 \n",
            "Train Epoch: 58 [160/245] \tLoss: 0.277850 \n",
            "Train Epoch: 58 [180/245] \tLoss: 0.427671 \n",
            "Train Epoch: 58 [200/245] \tLoss: 0.999544 \n",
            "Train Epoch: 58 [220/245] \tLoss: 0.505657 \n",
            "Train Epoch: 58 [240/245] \tLoss: 0.890906 \n",
            "\n",
            "Test set: Average loss: 1.0133, Accuracy: 501/992 (51%)\n",
            "\n",
            "Train Epoch: 59 [0/245] \tLoss: 1.035442 \n",
            "Train Epoch: 59 [20/245] \tLoss: 1.198165 \n",
            "Train Epoch: 59 [40/245] \tLoss: 0.499142 \n",
            "Train Epoch: 59 [60/245] \tLoss: 0.684688 \n",
            "Train Epoch: 59 [80/245] \tLoss: 0.552894 \n",
            "Train Epoch: 59 [100/245] \tLoss: 0.567486 \n",
            "Train Epoch: 59 [120/245] \tLoss: 0.557235 \n",
            "Train Epoch: 59 [140/245] \tLoss: 0.537978 \n",
            "Train Epoch: 59 [160/245] \tLoss: 0.277799 \n",
            "Train Epoch: 59 [180/245] \tLoss: 0.427682 \n",
            "Train Epoch: 59 [200/245] \tLoss: 0.999614 \n",
            "Train Epoch: 59 [220/245] \tLoss: 0.505817 \n",
            "Train Epoch: 59 [240/245] \tLoss: 0.890921 \n",
            "\n",
            "Test set: Average loss: 1.0134, Accuracy: 501/992 (51%)\n",
            "\n",
            "Train Epoch: 60 [0/245] \tLoss: 1.035363 \n",
            "Train Epoch: 60 [20/245] \tLoss: 1.197973 \n",
            "Train Epoch: 60 [40/245] \tLoss: 0.499047 \n",
            "Train Epoch: 60 [60/245] \tLoss: 0.684546 \n",
            "Train Epoch: 60 [80/245] \tLoss: 0.552884 \n",
            "Train Epoch: 60 [100/245] \tLoss: 0.567553 \n",
            "Train Epoch: 60 [120/245] \tLoss: 0.557252 \n",
            "Train Epoch: 60 [140/245] \tLoss: 0.537952 \n",
            "Train Epoch: 60 [160/245] \tLoss: 0.277753 \n",
            "Train Epoch: 60 [180/245] \tLoss: 0.427691 \n",
            "Train Epoch: 60 [200/245] \tLoss: 0.999681 \n",
            "Train Epoch: 60 [220/245] \tLoss: 0.505969 \n",
            "Train Epoch: 60 [240/245] \tLoss: 0.890942 \n",
            "\n",
            "Test set: Average loss: 1.0134, Accuracy: 501/992 (51%)\n",
            "\n",
            "Train Epoch: 61 [0/245] \tLoss: 1.035282 \n",
            "Train Epoch: 61 [20/245] \tLoss: 1.197787 \n",
            "Train Epoch: 61 [40/245] \tLoss: 0.498953 \n",
            "Train Epoch: 61 [60/245] \tLoss: 0.684408 \n",
            "Train Epoch: 61 [80/245] \tLoss: 0.552875 \n",
            "Train Epoch: 61 [100/245] \tLoss: 0.567616 \n",
            "Train Epoch: 61 [120/245] \tLoss: 0.557270 \n",
            "Train Epoch: 61 [140/245] \tLoss: 0.537925 \n",
            "Train Epoch: 61 [160/245] \tLoss: 0.277710 \n",
            "Train Epoch: 61 [180/245] \tLoss: 0.427699 \n",
            "Train Epoch: 61 [200/245] \tLoss: 0.999747 \n",
            "Train Epoch: 61 [220/245] \tLoss: 0.506114 \n",
            "Train Epoch: 61 [240/245] \tLoss: 0.890964 \n",
            "\n",
            "Test set: Average loss: 1.0134, Accuracy: 500/992 (50%)\n",
            "\n",
            "Train Epoch: 62 [0/245] \tLoss: 1.035196 \n",
            "Train Epoch: 62 [20/245] \tLoss: 1.197607 \n",
            "Train Epoch: 62 [40/245] \tLoss: 0.498863 \n",
            "Train Epoch: 62 [60/245] \tLoss: 0.684273 \n",
            "Train Epoch: 62 [80/245] \tLoss: 0.552867 \n",
            "Train Epoch: 62 [100/245] \tLoss: 0.567673 \n",
            "Train Epoch: 62 [120/245] \tLoss: 0.557289 \n",
            "Train Epoch: 62 [140/245] \tLoss: 0.537898 \n",
            "Train Epoch: 62 [160/245] \tLoss: 0.277671 \n",
            "Train Epoch: 62 [180/245] \tLoss: 0.427706 \n",
            "Train Epoch: 62 [200/245] \tLoss: 0.999809 \n",
            "Train Epoch: 62 [220/245] \tLoss: 0.506251 \n",
            "Train Epoch: 62 [240/245] \tLoss: 0.890991 \n",
            "\n",
            "Test set: Average loss: 1.0134, Accuracy: 500/992 (50%)\n",
            "\n",
            "Train Epoch: 63 [0/245] \tLoss: 1.035113 \n",
            "Train Epoch: 63 [20/245] \tLoss: 1.197433 \n",
            "Train Epoch: 63 [40/245] \tLoss: 0.498775 \n",
            "Train Epoch: 63 [60/245] \tLoss: 0.684141 \n",
            "Train Epoch: 63 [80/245] \tLoss: 0.552859 \n",
            "Train Epoch: 63 [100/245] \tLoss: 0.567726 \n",
            "Train Epoch: 63 [120/245] \tLoss: 0.557308 \n",
            "Train Epoch: 63 [140/245] \tLoss: 0.537871 \n",
            "Train Epoch: 63 [160/245] \tLoss: 0.277635 \n",
            "Train Epoch: 63 [180/245] \tLoss: 0.427712 \n",
            "Train Epoch: 63 [200/245] \tLoss: 0.999869 \n",
            "Train Epoch: 63 [220/245] \tLoss: 0.506382 \n",
            "Train Epoch: 63 [240/245] \tLoss: 0.891021 \n",
            "\n",
            "Test set: Average loss: 1.0134, Accuracy: 500/992 (50%)\n",
            "\n",
            "Train Epoch: 64 [0/245] \tLoss: 1.035025 \n",
            "Train Epoch: 64 [20/245] \tLoss: 1.197266 \n",
            "Train Epoch: 64 [40/245] \tLoss: 0.498690 \n",
            "Train Epoch: 64 [60/245] \tLoss: 0.684013 \n",
            "Train Epoch: 64 [80/245] \tLoss: 0.552852 \n",
            "Train Epoch: 64 [100/245] \tLoss: 0.567776 \n",
            "Train Epoch: 64 [120/245] \tLoss: 0.557328 \n",
            "Train Epoch: 64 [140/245] \tLoss: 0.537845 \n",
            "Train Epoch: 64 [160/245] \tLoss: 0.277603 \n",
            "Train Epoch: 64 [180/245] \tLoss: 0.427718 \n",
            "Train Epoch: 64 [200/245] \tLoss: 0.999927 \n",
            "Train Epoch: 64 [220/245] \tLoss: 0.506506 \n",
            "Train Epoch: 64 [240/245] \tLoss: 0.891053 \n",
            "\n",
            "Test set: Average loss: 1.0134, Accuracy: 499/992 (50%)\n",
            "\n",
            "Train Epoch: 65 [0/245] \tLoss: 1.034938 \n",
            "Train Epoch: 65 [20/245] \tLoss: 1.197104 \n",
            "Train Epoch: 65 [40/245] \tLoss: 0.498609 \n",
            "Train Epoch: 65 [60/245] \tLoss: 0.683887 \n",
            "Train Epoch: 65 [80/245] \tLoss: 0.552845 \n",
            "Train Epoch: 65 [100/245] \tLoss: 0.567822 \n",
            "Train Epoch: 65 [120/245] \tLoss: 0.557348 \n",
            "Train Epoch: 65 [140/245] \tLoss: 0.537819 \n",
            "Train Epoch: 65 [160/245] \tLoss: 0.277573 \n",
            "Train Epoch: 65 [180/245] \tLoss: 0.427722 \n",
            "Train Epoch: 65 [200/245] \tLoss: 0.999984 \n",
            "Train Epoch: 65 [220/245] \tLoss: 0.506625 \n",
            "Train Epoch: 65 [240/245] \tLoss: 0.891087 \n",
            "\n",
            "Test set: Average loss: 1.0134, Accuracy: 499/992 (50%)\n",
            "\n",
            "Train Epoch: 66 [0/245] \tLoss: 1.034851 \n",
            "Train Epoch: 66 [20/245] \tLoss: 1.196946 \n",
            "Train Epoch: 66 [40/245] \tLoss: 0.498529 \n",
            "Train Epoch: 66 [60/245] \tLoss: 0.683763 \n",
            "Train Epoch: 66 [80/245] \tLoss: 0.552840 \n",
            "Train Epoch: 66 [100/245] \tLoss: 0.567864 \n",
            "Train Epoch: 66 [120/245] \tLoss: 0.557369 \n",
            "Train Epoch: 66 [140/245] \tLoss: 0.537793 \n",
            "Train Epoch: 66 [160/245] \tLoss: 0.277545 \n",
            "Train Epoch: 66 [180/245] \tLoss: 0.427725 \n",
            "Train Epoch: 66 [200/245] \tLoss: 1.000038 \n",
            "Train Epoch: 66 [220/245] \tLoss: 0.506739 \n",
            "Train Epoch: 66 [240/245] \tLoss: 0.891124 \n",
            "\n",
            "Test set: Average loss: 1.0134, Accuracy: 499/992 (50%)\n",
            "\n",
            "Train Epoch: 67 [0/245] \tLoss: 1.034764 \n",
            "Train Epoch: 67 [20/245] \tLoss: 1.196795 \n",
            "Train Epoch: 67 [40/245] \tLoss: 0.498453 \n",
            "Train Epoch: 67 [60/245] \tLoss: 0.683644 \n",
            "Train Epoch: 67 [80/245] \tLoss: 0.552834 \n",
            "Train Epoch: 67 [100/245] \tLoss: 0.567905 \n",
            "Train Epoch: 67 [120/245] \tLoss: 0.557389 \n",
            "Train Epoch: 67 [140/245] \tLoss: 0.537767 \n",
            "Train Epoch: 67 [160/245] \tLoss: 0.277520 \n",
            "Train Epoch: 67 [180/245] \tLoss: 0.427728 \n",
            "Train Epoch: 67 [200/245] \tLoss: 1.000091 \n",
            "Train Epoch: 67 [220/245] \tLoss: 0.506847 \n",
            "Train Epoch: 67 [240/245] \tLoss: 0.891162 \n",
            "\n",
            "Test set: Average loss: 1.0134, Accuracy: 499/992 (50%)\n",
            "\n",
            "Train Epoch: 68 [0/245] \tLoss: 1.034677 \n",
            "Train Epoch: 68 [20/245] \tLoss: 1.196647 \n",
            "Train Epoch: 68 [40/245] \tLoss: 0.498379 \n",
            "Train Epoch: 68 [60/245] \tLoss: 0.683525 \n",
            "Train Epoch: 68 [80/245] \tLoss: 0.552829 \n",
            "Train Epoch: 68 [100/245] \tLoss: 0.567942 \n",
            "Train Epoch: 68 [120/245] \tLoss: 0.557410 \n",
            "Train Epoch: 68 [140/245] \tLoss: 0.537742 \n",
            "Train Epoch: 68 [160/245] \tLoss: 0.277497 \n",
            "Train Epoch: 68 [180/245] \tLoss: 0.427730 \n",
            "Train Epoch: 68 [200/245] \tLoss: 1.000141 \n",
            "Train Epoch: 68 [220/245] \tLoss: 0.506950 \n",
            "Train Epoch: 68 [240/245] \tLoss: 0.891201 \n",
            "\n",
            "Test set: Average loss: 1.0134, Accuracy: 499/992 (50%)\n",
            "\n",
            "Train Epoch: 69 [0/245] \tLoss: 1.034589 \n",
            "Train Epoch: 69 [20/245] \tLoss: 1.196505 \n",
            "Train Epoch: 69 [40/245] \tLoss: 0.498307 \n",
            "Train Epoch: 69 [60/245] \tLoss: 0.683410 \n",
            "Train Epoch: 69 [80/245] \tLoss: 0.552825 \n",
            "Train Epoch: 69 [100/245] \tLoss: 0.567976 \n",
            "Train Epoch: 69 [120/245] \tLoss: 0.557432 \n",
            "Train Epoch: 69 [140/245] \tLoss: 0.537715 \n",
            "Train Epoch: 69 [160/245] \tLoss: 0.277476 \n",
            "Train Epoch: 69 [180/245] \tLoss: 0.427732 \n",
            "Train Epoch: 69 [200/245] \tLoss: 1.000189 \n",
            "Train Epoch: 69 [220/245] \tLoss: 0.507049 \n",
            "Train Epoch: 69 [240/245] \tLoss: 0.891242 \n",
            "\n",
            "Test set: Average loss: 1.0134, Accuracy: 499/992 (50%)\n",
            "\n",
            "Train Epoch: 70 [0/245] \tLoss: 1.034503 \n",
            "Train Epoch: 70 [20/245] \tLoss: 1.196367 \n",
            "Train Epoch: 70 [40/245] \tLoss: 0.498238 \n",
            "Train Epoch: 70 [60/245] \tLoss: 0.683296 \n",
            "Train Epoch: 70 [80/245] \tLoss: 0.552820 \n",
            "Train Epoch: 70 [100/245] \tLoss: 0.568008 \n",
            "Train Epoch: 70 [120/245] \tLoss: 0.557453 \n",
            "Train Epoch: 70 [140/245] \tLoss: 0.537689 \n",
            "Train Epoch: 70 [160/245] \tLoss: 0.277457 \n",
            "Train Epoch: 70 [180/245] \tLoss: 0.427733 \n",
            "Train Epoch: 70 [200/245] \tLoss: 1.000238 \n",
            "Train Epoch: 70 [220/245] \tLoss: 0.507143 \n",
            "Train Epoch: 70 [240/245] \tLoss: 0.891284 \n",
            "\n",
            "Test set: Average loss: 1.0134, Accuracy: 499/992 (50%)\n",
            "\n",
            "Train Epoch: 71 [0/245] \tLoss: 1.034416 \n",
            "Train Epoch: 71 [20/245] \tLoss: 1.196232 \n",
            "Train Epoch: 71 [40/245] \tLoss: 0.498171 \n",
            "Train Epoch: 71 [60/245] \tLoss: 0.683185 \n",
            "Train Epoch: 71 [80/245] \tLoss: 0.552816 \n",
            "Train Epoch: 71 [100/245] \tLoss: 0.568039 \n",
            "Train Epoch: 71 [120/245] \tLoss: 0.557474 \n",
            "Train Epoch: 71 [140/245] \tLoss: 0.537662 \n",
            "Train Epoch: 71 [160/245] \tLoss: 0.277439 \n",
            "Train Epoch: 71 [180/245] \tLoss: 0.427733 \n",
            "Train Epoch: 71 [200/245] \tLoss: 1.000284 \n",
            "Train Epoch: 71 [220/245] \tLoss: 0.507234 \n",
            "Train Epoch: 71 [240/245] \tLoss: 0.891327 \n",
            "\n",
            "Test set: Average loss: 1.0134, Accuracy: 499/992 (50%)\n",
            "\n",
            "Train Epoch: 72 [0/245] \tLoss: 1.034333 \n",
            "Train Epoch: 72 [20/245] \tLoss: 1.196100 \n",
            "Train Epoch: 72 [40/245] \tLoss: 0.498107 \n",
            "Train Epoch: 72 [60/245] \tLoss: 0.683075 \n",
            "Train Epoch: 72 [80/245] \tLoss: 0.552812 \n",
            "Train Epoch: 72 [100/245] \tLoss: 0.568067 \n",
            "Train Epoch: 72 [120/245] \tLoss: 0.557496 \n",
            "Train Epoch: 72 [140/245] \tLoss: 0.537636 \n",
            "Train Epoch: 72 [160/245] \tLoss: 0.277423 \n",
            "Train Epoch: 72 [180/245] \tLoss: 0.427733 \n",
            "Train Epoch: 72 [200/245] \tLoss: 1.000329 \n",
            "Train Epoch: 72 [220/245] \tLoss: 0.507322 \n",
            "Train Epoch: 72 [240/245] \tLoss: 0.891371 \n",
            "\n",
            "Test set: Average loss: 1.0134, Accuracy: 499/992 (50%)\n",
            "\n",
            "Train Epoch: 73 [0/245] \tLoss: 1.034250 \n",
            "Train Epoch: 73 [20/245] \tLoss: 1.195973 \n",
            "Train Epoch: 73 [40/245] \tLoss: 0.498045 \n",
            "Train Epoch: 73 [60/245] \tLoss: 0.682968 \n",
            "Train Epoch: 73 [80/245] \tLoss: 0.552809 \n",
            "Train Epoch: 73 [100/245] \tLoss: 0.568094 \n",
            "Train Epoch: 73 [120/245] \tLoss: 0.557517 \n",
            "Train Epoch: 73 [140/245] \tLoss: 0.537610 \n",
            "Train Epoch: 73 [160/245] \tLoss: 0.277407 \n",
            "Train Epoch: 73 [180/245] \tLoss: 0.427732 \n",
            "Train Epoch: 73 [200/245] \tLoss: 1.000373 \n",
            "Train Epoch: 73 [220/245] \tLoss: 0.507405 \n",
            "Train Epoch: 73 [240/245] \tLoss: 0.891415 \n",
            "\n",
            "Test set: Average loss: 1.0134, Accuracy: 499/992 (50%)\n",
            "\n",
            "Train Epoch: 74 [0/245] \tLoss: 1.034166 \n",
            "Train Epoch: 74 [20/245] \tLoss: 1.195849 \n",
            "Train Epoch: 74 [40/245] \tLoss: 0.497984 \n",
            "Train Epoch: 74 [60/245] \tLoss: 0.682862 \n",
            "Train Epoch: 74 [80/245] \tLoss: 0.552806 \n",
            "Train Epoch: 74 [100/245] \tLoss: 0.568119 \n",
            "Train Epoch: 74 [120/245] \tLoss: 0.557539 \n",
            "Train Epoch: 74 [140/245] \tLoss: 0.537583 \n",
            "Train Epoch: 74 [160/245] \tLoss: 0.277394 \n",
            "Train Epoch: 74 [180/245] \tLoss: 0.427731 \n",
            "Train Epoch: 74 [200/245] \tLoss: 1.000415 \n",
            "Train Epoch: 74 [220/245] \tLoss: 0.507485 \n",
            "Train Epoch: 74 [240/245] \tLoss: 0.891459 \n",
            "\n",
            "Test set: Average loss: 1.0134, Accuracy: 499/992 (50%)\n",
            "\n",
            "Train Epoch: 75 [0/245] \tLoss: 1.034084 \n",
            "Train Epoch: 75 [20/245] \tLoss: 1.195728 \n",
            "Train Epoch: 75 [40/245] \tLoss: 0.497926 \n",
            "Train Epoch: 75 [60/245] \tLoss: 0.682758 \n",
            "Train Epoch: 75 [80/245] \tLoss: 0.552803 \n",
            "Train Epoch: 75 [100/245] \tLoss: 0.568142 \n",
            "Train Epoch: 75 [120/245] \tLoss: 0.557560 \n",
            "Train Epoch: 75 [140/245] \tLoss: 0.537556 \n",
            "Train Epoch: 75 [160/245] \tLoss: 0.277381 \n",
            "Train Epoch: 75 [180/245] \tLoss: 0.427730 \n",
            "Train Epoch: 75 [200/245] \tLoss: 1.000457 \n",
            "Train Epoch: 75 [220/245] \tLoss: 0.507562 \n",
            "Train Epoch: 75 [240/245] \tLoss: 0.891504 \n",
            "\n",
            "Test set: Average loss: 1.0133, Accuracy: 499/992 (50%)\n",
            "\n",
            "Train Epoch: 76 [0/245] \tLoss: 1.034002 \n",
            "Train Epoch: 76 [20/245] \tLoss: 1.195611 \n",
            "Train Epoch: 76 [40/245] \tLoss: 0.497868 \n",
            "Train Epoch: 76 [60/245] \tLoss: 0.682656 \n",
            "Train Epoch: 76 [80/245] \tLoss: 0.552800 \n",
            "Train Epoch: 76 [100/245] \tLoss: 0.568165 \n",
            "Train Epoch: 76 [120/245] \tLoss: 0.557582 \n",
            "Train Epoch: 76 [140/245] \tLoss: 0.537530 \n",
            "Train Epoch: 76 [160/245] \tLoss: 0.277369 \n",
            "Train Epoch: 76 [180/245] \tLoss: 0.427728 \n",
            "Train Epoch: 76 [200/245] \tLoss: 1.000497 \n",
            "Train Epoch: 76 [220/245] \tLoss: 0.507636 \n",
            "Train Epoch: 76 [240/245] \tLoss: 0.891549 \n",
            "\n",
            "Test set: Average loss: 1.0133, Accuracy: 499/992 (50%)\n",
            "\n",
            "Train Epoch: 77 [0/245] \tLoss: 1.033922 \n",
            "Train Epoch: 77 [20/245] \tLoss: 1.195497 \n",
            "Train Epoch: 77 [40/245] \tLoss: 0.497814 \n",
            "Train Epoch: 77 [60/245] \tLoss: 0.682555 \n",
            "Train Epoch: 77 [80/245] \tLoss: 0.552798 \n",
            "Train Epoch: 77 [100/245] \tLoss: 0.568186 \n",
            "Train Epoch: 77 [120/245] \tLoss: 0.557603 \n",
            "Train Epoch: 77 [140/245] \tLoss: 0.537504 \n",
            "Train Epoch: 77 [160/245] \tLoss: 0.277358 \n",
            "Train Epoch: 77 [180/245] \tLoss: 0.427726 \n",
            "Train Epoch: 77 [200/245] \tLoss: 1.000535 \n",
            "Train Epoch: 77 [220/245] \tLoss: 0.507706 \n",
            "Train Epoch: 77 [240/245] \tLoss: 0.891594 \n",
            "\n",
            "Test set: Average loss: 1.0133, Accuracy: 499/992 (50%)\n",
            "\n",
            "Train Epoch: 78 [0/245] \tLoss: 1.033841 \n",
            "Train Epoch: 78 [20/245] \tLoss: 1.195386 \n",
            "Train Epoch: 78 [40/245] \tLoss: 0.497760 \n",
            "Train Epoch: 78 [60/245] \tLoss: 0.682456 \n",
            "Train Epoch: 78 [80/245] \tLoss: 0.552796 \n",
            "Train Epoch: 78 [100/245] \tLoss: 0.568205 \n",
            "Train Epoch: 78 [120/245] \tLoss: 0.557624 \n",
            "Train Epoch: 78 [140/245] \tLoss: 0.537477 \n",
            "Train Epoch: 78 [160/245] \tLoss: 0.277348 \n",
            "Train Epoch: 78 [180/245] \tLoss: 0.427724 \n",
            "Train Epoch: 78 [200/245] \tLoss: 1.000573 \n",
            "Train Epoch: 78 [220/245] \tLoss: 0.507775 \n",
            "Train Epoch: 78 [240/245] \tLoss: 0.891639 \n",
            "\n",
            "Test set: Average loss: 1.0133, Accuracy: 499/992 (50%)\n",
            "\n",
            "Train Epoch: 79 [0/245] \tLoss: 1.033762 \n",
            "Train Epoch: 79 [20/245] \tLoss: 1.195278 \n",
            "Train Epoch: 79 [40/245] \tLoss: 0.497708 \n",
            "Train Epoch: 79 [60/245] \tLoss: 0.682358 \n",
            "Train Epoch: 79 [80/245] \tLoss: 0.552794 \n",
            "Train Epoch: 79 [100/245] \tLoss: 0.568225 \n",
            "Train Epoch: 79 [120/245] \tLoss: 0.557645 \n",
            "Train Epoch: 79 [140/245] \tLoss: 0.537450 \n",
            "Train Epoch: 79 [160/245] \tLoss: 0.277338 \n",
            "Train Epoch: 79 [180/245] \tLoss: 0.427721 \n",
            "Train Epoch: 79 [200/245] \tLoss: 1.000609 \n",
            "Train Epoch: 79 [220/245] \tLoss: 0.507841 \n",
            "Train Epoch: 79 [240/245] \tLoss: 0.891683 \n",
            "\n",
            "Test set: Average loss: 1.0132, Accuracy: 500/992 (50%)\n",
            "\n",
            "Train Epoch: 80 [0/245] \tLoss: 1.033683 \n",
            "Train Epoch: 80 [20/245] \tLoss: 1.195172 \n",
            "Train Epoch: 80 [40/245] \tLoss: 0.497658 \n",
            "Train Epoch: 80 [60/245] \tLoss: 0.682262 \n",
            "Train Epoch: 80 [80/245] \tLoss: 0.552792 \n",
            "Train Epoch: 80 [100/245] \tLoss: 0.568242 \n",
            "Train Epoch: 80 [120/245] \tLoss: 0.557666 \n",
            "Train Epoch: 80 [140/245] \tLoss: 0.537423 \n",
            "Train Epoch: 80 [160/245] \tLoss: 0.277330 \n",
            "Train Epoch: 80 [180/245] \tLoss: 0.427718 \n",
            "Train Epoch: 80 [200/245] \tLoss: 1.000645 \n",
            "Train Epoch: 80 [220/245] \tLoss: 0.507903 \n",
            "Train Epoch: 80 [240/245] \tLoss: 0.891728 \n",
            "\n",
            "Test set: Average loss: 1.0132, Accuracy: 500/992 (50%)\n",
            "\n",
            "Train Epoch: 81 [0/245] \tLoss: 1.033605 \n",
            "Train Epoch: 81 [20/245] \tLoss: 1.195070 \n",
            "Train Epoch: 81 [40/245] \tLoss: 0.497610 \n",
            "Train Epoch: 81 [60/245] \tLoss: 0.682167 \n",
            "Train Epoch: 81 [80/245] \tLoss: 0.552791 \n",
            "Train Epoch: 81 [100/245] \tLoss: 0.568259 \n",
            "Train Epoch: 81 [120/245] \tLoss: 0.557687 \n",
            "Train Epoch: 81 [140/245] \tLoss: 0.537397 \n",
            "Train Epoch: 81 [160/245] \tLoss: 0.277322 \n",
            "Train Epoch: 81 [180/245] \tLoss: 0.427715 \n",
            "Train Epoch: 81 [200/245] \tLoss: 1.000680 \n",
            "Train Epoch: 81 [220/245] \tLoss: 0.507964 \n",
            "Train Epoch: 81 [240/245] \tLoss: 0.891773 \n",
            "\n",
            "Test set: Average loss: 1.0132, Accuracy: 500/992 (50%)\n",
            "\n",
            "Train Epoch: 82 [0/245] \tLoss: 1.033529 \n",
            "Train Epoch: 82 [20/245] \tLoss: 1.194969 \n",
            "Train Epoch: 82 [40/245] \tLoss: 0.497563 \n",
            "Train Epoch: 82 [60/245] \tLoss: 0.682073 \n",
            "Train Epoch: 82 [80/245] \tLoss: 0.552790 \n",
            "Train Epoch: 82 [100/245] \tLoss: 0.568276 \n",
            "Train Epoch: 82 [120/245] \tLoss: 0.557707 \n",
            "Train Epoch: 82 [140/245] \tLoss: 0.537370 \n",
            "Train Epoch: 82 [160/245] \tLoss: 0.277314 \n",
            "Train Epoch: 82 [180/245] \tLoss: 0.427712 \n",
            "Train Epoch: 82 [200/245] \tLoss: 1.000715 \n",
            "Train Epoch: 82 [220/245] \tLoss: 0.508023 \n",
            "Train Epoch: 82 [240/245] \tLoss: 0.891817 \n",
            "\n",
            "Test set: Average loss: 1.0132, Accuracy: 500/992 (50%)\n",
            "\n",
            "Train Epoch: 83 [0/245] \tLoss: 1.033455 \n",
            "Train Epoch: 83 [20/245] \tLoss: 1.194871 \n",
            "Train Epoch: 83 [40/245] \tLoss: 0.497517 \n",
            "Train Epoch: 83 [60/245] \tLoss: 0.681981 \n",
            "Train Epoch: 83 [80/245] \tLoss: 0.552789 \n",
            "Train Epoch: 83 [100/245] \tLoss: 0.568291 \n",
            "Train Epoch: 83 [120/245] \tLoss: 0.557728 \n",
            "Train Epoch: 83 [140/245] \tLoss: 0.537344 \n",
            "Train Epoch: 83 [160/245] \tLoss: 0.277307 \n",
            "Train Epoch: 83 [180/245] \tLoss: 0.427708 \n",
            "Train Epoch: 83 [200/245] \tLoss: 1.000749 \n",
            "Train Epoch: 83 [220/245] \tLoss: 0.508080 \n",
            "Train Epoch: 83 [240/245] \tLoss: 0.891861 \n",
            "\n",
            "Test set: Average loss: 1.0131, Accuracy: 500/992 (50%)\n",
            "\n",
            "Train Epoch: 84 [0/245] \tLoss: 1.033380 \n",
            "Train Epoch: 84 [20/245] \tLoss: 1.194774 \n",
            "Train Epoch: 84 [40/245] \tLoss: 0.497474 \n",
            "Train Epoch: 84 [60/245] \tLoss: 0.681890 \n",
            "Train Epoch: 84 [80/245] \tLoss: 0.552787 \n",
            "Train Epoch: 84 [100/245] \tLoss: 0.568305 \n",
            "Train Epoch: 84 [120/245] \tLoss: 0.557748 \n",
            "Train Epoch: 84 [140/245] \tLoss: 0.537318 \n",
            "Train Epoch: 84 [160/245] \tLoss: 0.277301 \n",
            "Train Epoch: 84 [180/245] \tLoss: 0.427705 \n",
            "Train Epoch: 84 [200/245] \tLoss: 1.000782 \n",
            "Train Epoch: 84 [220/245] \tLoss: 0.508135 \n",
            "Train Epoch: 84 [240/245] \tLoss: 0.891905 \n",
            "\n",
            "Test set: Average loss: 1.0131, Accuracy: 500/992 (50%)\n",
            "\n",
            "Train Epoch: 85 [0/245] \tLoss: 1.033310 \n",
            "Train Epoch: 85 [20/245] \tLoss: 1.194680 \n",
            "Train Epoch: 85 [40/245] \tLoss: 0.497431 \n",
            "Train Epoch: 85 [60/245] \tLoss: 0.681800 \n",
            "Train Epoch: 85 [80/245] \tLoss: 0.552787 \n",
            "Train Epoch: 85 [100/245] \tLoss: 0.568320 \n",
            "Train Epoch: 85 [120/245] \tLoss: 0.557768 \n",
            "Train Epoch: 85 [140/245] \tLoss: 0.537291 \n",
            "Train Epoch: 85 [160/245] \tLoss: 0.277295 \n",
            "Train Epoch: 85 [180/245] \tLoss: 0.427701 \n",
            "Train Epoch: 85 [200/245] \tLoss: 1.000814 \n",
            "Train Epoch: 85 [220/245] \tLoss: 0.508189 \n",
            "Train Epoch: 85 [240/245] \tLoss: 0.891949 \n",
            "\n",
            "Test set: Average loss: 1.0131, Accuracy: 500/992 (50%)\n",
            "\n",
            "Train Epoch: 86 [0/245] \tLoss: 1.033239 \n",
            "Train Epoch: 86 [20/245] \tLoss: 1.194587 \n",
            "Train Epoch: 86 [40/245] \tLoss: 0.497389 \n",
            "Train Epoch: 86 [60/245] \tLoss: 0.681711 \n",
            "Train Epoch: 86 [80/245] \tLoss: 0.552786 \n",
            "Train Epoch: 86 [100/245] \tLoss: 0.568333 \n",
            "Train Epoch: 86 [120/245] \tLoss: 0.557787 \n",
            "Train Epoch: 86 [140/245] \tLoss: 0.537265 \n",
            "Train Epoch: 86 [160/245] \tLoss: 0.277290 \n",
            "Train Epoch: 86 [180/245] \tLoss: 0.427697 \n",
            "Train Epoch: 86 [200/245] \tLoss: 1.000846 \n",
            "Train Epoch: 86 [220/245] \tLoss: 0.508240 \n",
            "Train Epoch: 86 [240/245] \tLoss: 0.891991 \n",
            "\n",
            "Test set: Average loss: 1.0131, Accuracy: 500/992 (50%)\n",
            "\n",
            "Train Epoch: 87 [0/245] \tLoss: 1.033168 \n",
            "Train Epoch: 87 [20/245] \tLoss: 1.194497 \n",
            "Train Epoch: 87 [40/245] \tLoss: 0.497349 \n",
            "Train Epoch: 87 [60/245] \tLoss: 0.681623 \n",
            "Train Epoch: 87 [80/245] \tLoss: 0.552785 \n",
            "Train Epoch: 87 [100/245] \tLoss: 0.568346 \n",
            "Train Epoch: 87 [120/245] \tLoss: 0.557807 \n",
            "Train Epoch: 87 [140/245] \tLoss: 0.537238 \n",
            "Train Epoch: 87 [160/245] \tLoss: 0.277285 \n",
            "Train Epoch: 87 [180/245] \tLoss: 0.427693 \n",
            "Train Epoch: 87 [200/245] \tLoss: 1.000877 \n",
            "Train Epoch: 87 [220/245] \tLoss: 0.508290 \n",
            "Train Epoch: 87 [240/245] \tLoss: 0.892034 \n",
            "\n",
            "Test set: Average loss: 1.0130, Accuracy: 500/992 (50%)\n",
            "\n",
            "Train Epoch: 88 [0/245] \tLoss: 1.033100 \n",
            "Train Epoch: 88 [20/245] \tLoss: 1.194409 \n",
            "Train Epoch: 88 [40/245] \tLoss: 0.497311 \n",
            "Train Epoch: 88 [60/245] \tLoss: 0.681536 \n",
            "Train Epoch: 88 [80/245] \tLoss: 0.552784 \n",
            "Train Epoch: 88 [100/245] \tLoss: 0.568359 \n",
            "Train Epoch: 88 [120/245] \tLoss: 0.557826 \n",
            "Train Epoch: 88 [140/245] \tLoss: 0.537211 \n",
            "Train Epoch: 88 [160/245] \tLoss: 0.277280 \n",
            "Train Epoch: 88 [180/245] \tLoss: 0.427689 \n",
            "Train Epoch: 88 [200/245] \tLoss: 1.000907 \n",
            "Train Epoch: 88 [220/245] \tLoss: 0.508339 \n",
            "Train Epoch: 88 [240/245] \tLoss: 0.892077 \n",
            "\n",
            "Test set: Average loss: 1.0130, Accuracy: 500/992 (50%)\n",
            "\n",
            "Train Epoch: 89 [0/245] \tLoss: 1.033034 \n",
            "Train Epoch: 89 [20/245] \tLoss: 1.194322 \n",
            "Train Epoch: 89 [40/245] \tLoss: 0.497273 \n",
            "Train Epoch: 89 [60/245] \tLoss: 0.681450 \n",
            "Train Epoch: 89 [80/245] \tLoss: 0.552783 \n",
            "Train Epoch: 89 [100/245] \tLoss: 0.568371 \n",
            "Train Epoch: 89 [120/245] \tLoss: 0.557845 \n",
            "Train Epoch: 89 [140/245] \tLoss: 0.537185 \n",
            "Train Epoch: 89 [160/245] \tLoss: 0.277275 \n",
            "Train Epoch: 89 [180/245] \tLoss: 0.427684 \n",
            "Train Epoch: 89 [200/245] \tLoss: 1.000937 \n",
            "Train Epoch: 89 [220/245] \tLoss: 0.508385 \n",
            "Train Epoch: 89 [240/245] \tLoss: 0.892119 \n",
            "\n",
            "Test set: Average loss: 1.0130, Accuracy: 500/992 (50%)\n",
            "\n",
            "Train Epoch: 90 [0/245] \tLoss: 1.032969 \n",
            "Train Epoch: 90 [20/245] \tLoss: 1.194238 \n",
            "Train Epoch: 90 [40/245] \tLoss: 0.497236 \n",
            "Train Epoch: 90 [60/245] \tLoss: 0.681365 \n",
            "Train Epoch: 90 [80/245] \tLoss: 0.552783 \n",
            "Train Epoch: 90 [100/245] \tLoss: 0.568382 \n",
            "Train Epoch: 90 [120/245] \tLoss: 0.557864 \n",
            "Train Epoch: 90 [140/245] \tLoss: 0.537160 \n",
            "Train Epoch: 90 [160/245] \tLoss: 0.277271 \n",
            "Train Epoch: 90 [180/245] \tLoss: 0.427680 \n",
            "Train Epoch: 90 [200/245] \tLoss: 1.000966 \n",
            "Train Epoch: 90 [220/245] \tLoss: 0.508431 \n",
            "Train Epoch: 90 [240/245] \tLoss: 0.892160 \n",
            "\n",
            "Test set: Average loss: 1.0130, Accuracy: 500/992 (50%)\n",
            "\n",
            "Train Epoch: 91 [0/245] \tLoss: 1.032904 \n",
            "Train Epoch: 91 [20/245] \tLoss: 1.194155 \n",
            "Train Epoch: 91 [40/245] \tLoss: 0.497201 \n",
            "Train Epoch: 91 [60/245] \tLoss: 0.681281 \n",
            "Train Epoch: 91 [80/245] \tLoss: 0.552783 \n",
            "Train Epoch: 91 [100/245] \tLoss: 0.568394 \n",
            "Train Epoch: 91 [120/245] \tLoss: 0.557882 \n",
            "Train Epoch: 91 [140/245] \tLoss: 0.537134 \n",
            "Train Epoch: 91 [160/245] \tLoss: 0.277267 \n",
            "Train Epoch: 91 [180/245] \tLoss: 0.427676 \n",
            "Train Epoch: 91 [200/245] \tLoss: 1.000995 \n",
            "Train Epoch: 91 [220/245] \tLoss: 0.508475 \n",
            "Train Epoch: 91 [240/245] \tLoss: 0.892201 \n",
            "\n",
            "Test set: Average loss: 1.0129, Accuracy: 500/992 (50%)\n",
            "\n",
            "Train Epoch: 92 [0/245] \tLoss: 1.032840 \n",
            "Train Epoch: 92 [20/245] \tLoss: 1.194073 \n",
            "Train Epoch: 92 [40/245] \tLoss: 0.497166 \n",
            "Train Epoch: 92 [60/245] \tLoss: 0.681198 \n",
            "Train Epoch: 92 [80/245] \tLoss: 0.552782 \n",
            "Train Epoch: 92 [100/245] \tLoss: 0.568405 \n",
            "Train Epoch: 92 [120/245] \tLoss: 0.557900 \n",
            "Train Epoch: 92 [140/245] \tLoss: 0.537108 \n",
            "Train Epoch: 92 [160/245] \tLoss: 0.277263 \n",
            "Train Epoch: 92 [180/245] \tLoss: 0.427671 \n",
            "Train Epoch: 92 [200/245] \tLoss: 1.001024 \n",
            "Train Epoch: 92 [220/245] \tLoss: 0.508518 \n",
            "Train Epoch: 92 [240/245] \tLoss: 0.892242 \n",
            "\n",
            "Test set: Average loss: 1.0129, Accuracy: 500/992 (50%)\n",
            "\n",
            "Train Epoch: 93 [0/245] \tLoss: 1.032779 \n",
            "Train Epoch: 93 [20/245] \tLoss: 1.193993 \n",
            "Train Epoch: 93 [40/245] \tLoss: 0.497134 \n",
            "Train Epoch: 93 [60/245] \tLoss: 0.681115 \n",
            "Train Epoch: 93 [80/245] \tLoss: 0.552781 \n",
            "Train Epoch: 93 [100/245] \tLoss: 0.568416 \n",
            "Train Epoch: 93 [120/245] \tLoss: 0.557918 \n",
            "Train Epoch: 93 [140/245] \tLoss: 0.537082 \n",
            "Train Epoch: 93 [160/245] \tLoss: 0.277259 \n",
            "Train Epoch: 93 [180/245] \tLoss: 0.427667 \n",
            "Train Epoch: 93 [200/245] \tLoss: 1.001051 \n",
            "Train Epoch: 93 [220/245] \tLoss: 0.508560 \n",
            "Train Epoch: 93 [240/245] \tLoss: 0.892281 \n",
            "\n",
            "Test set: Average loss: 1.0129, Accuracy: 500/992 (50%)\n",
            "\n",
            "Train Epoch: 94 [0/245] \tLoss: 1.032718 \n",
            "Train Epoch: 94 [20/245] \tLoss: 1.193914 \n",
            "Train Epoch: 94 [40/245] \tLoss: 0.497101 \n",
            "Train Epoch: 94 [60/245] \tLoss: 0.681034 \n",
            "Train Epoch: 94 [80/245] \tLoss: 0.552781 \n",
            "Train Epoch: 94 [100/245] \tLoss: 0.568426 \n",
            "Train Epoch: 94 [120/245] \tLoss: 0.557935 \n",
            "Train Epoch: 94 [140/245] \tLoss: 0.537056 \n",
            "Train Epoch: 94 [160/245] \tLoss: 0.277256 \n",
            "Train Epoch: 94 [180/245] \tLoss: 0.427663 \n",
            "Train Epoch: 94 [200/245] \tLoss: 1.001079 \n",
            "Train Epoch: 94 [220/245] \tLoss: 0.508601 \n",
            "Train Epoch: 94 [240/245] \tLoss: 0.892322 \n",
            "\n",
            "Test set: Average loss: 1.0128, Accuracy: 500/992 (50%)\n",
            "\n",
            "Train Epoch: 95 [0/245] \tLoss: 1.032660 \n",
            "Train Epoch: 95 [20/245] \tLoss: 1.193836 \n",
            "Train Epoch: 95 [40/245] \tLoss: 0.497070 \n",
            "Train Epoch: 95 [60/245] \tLoss: 0.680953 \n",
            "Train Epoch: 95 [80/245] \tLoss: 0.552780 \n",
            "Train Epoch: 95 [100/245] \tLoss: 0.568436 \n",
            "Train Epoch: 95 [120/245] \tLoss: 0.557953 \n",
            "Train Epoch: 95 [140/245] \tLoss: 0.537031 \n",
            "Train Epoch: 95 [160/245] \tLoss: 0.277253 \n",
            "Train Epoch: 95 [180/245] \tLoss: 0.427658 \n",
            "Train Epoch: 95 [200/245] \tLoss: 1.001106 \n",
            "Train Epoch: 95 [220/245] \tLoss: 0.508640 \n",
            "Train Epoch: 95 [240/245] \tLoss: 0.892359 \n",
            "\n",
            "Test set: Average loss: 1.0128, Accuracy: 500/992 (50%)\n",
            "\n",
            "Train Epoch: 96 [0/245] \tLoss: 1.032600 \n",
            "Train Epoch: 96 [20/245] \tLoss: 1.193761 \n",
            "Train Epoch: 96 [40/245] \tLoss: 0.497039 \n",
            "Train Epoch: 96 [60/245] \tLoss: 0.680873 \n",
            "Train Epoch: 96 [80/245] \tLoss: 0.552780 \n",
            "Train Epoch: 96 [100/245] \tLoss: 0.568446 \n",
            "Train Epoch: 96 [120/245] \tLoss: 0.557970 \n",
            "Train Epoch: 96 [140/245] \tLoss: 0.537005 \n",
            "Train Epoch: 96 [160/245] \tLoss: 0.277249 \n",
            "Train Epoch: 96 [180/245] \tLoss: 0.427653 \n",
            "Train Epoch: 96 [200/245] \tLoss: 1.001132 \n",
            "Train Epoch: 96 [220/245] \tLoss: 0.508678 \n",
            "Train Epoch: 96 [240/245] \tLoss: 0.892398 \n",
            "\n",
            "Test set: Average loss: 1.0128, Accuracy: 500/992 (50%)\n",
            "\n",
            "Train Epoch: 97 [0/245] \tLoss: 1.032544 \n",
            "Train Epoch: 97 [20/245] \tLoss: 1.193686 \n",
            "Train Epoch: 97 [40/245] \tLoss: 0.497010 \n",
            "Train Epoch: 97 [60/245] \tLoss: 0.680794 \n",
            "Train Epoch: 97 [80/245] \tLoss: 0.552780 \n",
            "Train Epoch: 97 [100/245] \tLoss: 0.568455 \n",
            "Train Epoch: 97 [120/245] \tLoss: 0.557987 \n",
            "Train Epoch: 97 [140/245] \tLoss: 0.536980 \n",
            "Train Epoch: 97 [160/245] \tLoss: 0.277247 \n",
            "Train Epoch: 97 [180/245] \tLoss: 0.427649 \n",
            "Train Epoch: 97 [200/245] \tLoss: 1.001159 \n",
            "Train Epoch: 97 [220/245] \tLoss: 0.508716 \n",
            "Train Epoch: 97 [240/245] \tLoss: 0.892436 \n",
            "\n",
            "Test set: Average loss: 1.0128, Accuracy: 500/992 (50%)\n",
            "\n",
            "Train Epoch: 98 [0/245] \tLoss: 1.032489 \n",
            "Train Epoch: 98 [20/245] \tLoss: 1.193612 \n",
            "Train Epoch: 98 [40/245] \tLoss: 0.496982 \n",
            "Train Epoch: 98 [60/245] \tLoss: 0.680716 \n",
            "Train Epoch: 98 [80/245] \tLoss: 0.552779 \n",
            "Train Epoch: 98 [100/245] \tLoss: 0.568465 \n",
            "Train Epoch: 98 [120/245] \tLoss: 0.558003 \n",
            "Train Epoch: 98 [140/245] \tLoss: 0.536955 \n",
            "Train Epoch: 98 [160/245] \tLoss: 0.277244 \n",
            "Train Epoch: 98 [180/245] \tLoss: 0.427644 \n",
            "Train Epoch: 98 [200/245] \tLoss: 1.001185 \n",
            "Train Epoch: 98 [220/245] \tLoss: 0.508753 \n",
            "Train Epoch: 98 [240/245] \tLoss: 0.892474 \n",
            "\n",
            "Test set: Average loss: 1.0127, Accuracy: 500/992 (50%)\n",
            "\n",
            "Train Epoch: 99 [0/245] \tLoss: 1.032435 \n",
            "Train Epoch: 99 [20/245] \tLoss: 1.193540 \n",
            "Train Epoch: 99 [40/245] \tLoss: 0.496954 \n",
            "Train Epoch: 99 [60/245] \tLoss: 0.680638 \n",
            "Train Epoch: 99 [80/245] \tLoss: 0.552779 \n",
            "Train Epoch: 99 [100/245] \tLoss: 0.568474 \n",
            "Train Epoch: 99 [120/245] \tLoss: 0.558020 \n",
            "Train Epoch: 99 [140/245] \tLoss: 0.536930 \n",
            "Train Epoch: 99 [160/245] \tLoss: 0.277241 \n",
            "Train Epoch: 99 [180/245] \tLoss: 0.427640 \n",
            "Train Epoch: 99 [200/245] \tLoss: 1.001210 \n",
            "Train Epoch: 99 [220/245] \tLoss: 0.508789 \n",
            "Train Epoch: 99 [240/245] \tLoss: 0.892510 \n",
            "\n",
            "Test set: Average loss: 1.0127, Accuracy: 500/992 (50%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "nziVdgBi6plS",
        "outputId": "96195143-f255-4be8-bb2c-5df32b887007"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x = range(1, 24250, 245)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(15, 5))\n",
        "ax.plot(list_loss_train[200:5000], label='train')\n",
        "ax.plot(x[:25], list_loss_test[:25], label='test')\n",
        "\n",
        "ax.set_xlabel('iter')\n",
        "ax.set_ylabel('loss')\n",
        "\n",
        "plt.title('Loss')\n",
        "plt.legend();"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQwtxhweVxbz",
        "outputId": "42ab2bbd-09a0-4a0f-dd24-6fe1fb463c67"
      },
      "source": [
        "fn = nn.MSELoss()\n",
        "loss = fn(torch.tensor([1., 2., 3.]), torch.tensor([4., 5., 6.]))\n",
        "loss"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(9.)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    }
  ]
}